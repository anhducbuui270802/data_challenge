{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22259,"status":"ok","timestamp":1697907763847,"user":{"displayName":"Đức Bùi Duy Anh","userId":"13275453910777475613"},"user_tz":-420},"id":"EstZfJl_hbM-","outputId":"74c2fe21-1e01-4b95-fe5f-56ee9a876377"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":81842,"status":"ok","timestamp":1697907845684,"user":{"displayName":"Đức Bùi Duy Anh","userId":"13275453910777475613"},"user_tz":-420},"id":"eDY5Uvl0ElA0","outputId":"2426355a-d155-4713-96c1-6dfdf33ffc3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers<0.15,>=0.14 (from transformers)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.1\n","Collecting fairseq\n","  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.16.0)\n","Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq) (3.0.4)\n","Collecting hydra-core<1.1,>=1.0.7 (from fairseq)\n","  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting omegaconf<2.1 (from fairseq)\n","  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq) (2023.6.3)\n","Collecting sacrebleu>=1.4.12 (from fairseq)\n","  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.1.0+cu118)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq) (4.66.1)\n","Collecting bitarray (from fairseq)\n","  Downloading bitarray-2.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (286 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.5/286.5 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.1.0+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.23.5)\n","Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq)\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (6.0.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (4.5.0)\n","Collecting portalocker (from sacrebleu>=1.4.12->fairseq)\n","  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.9.0)\n","Collecting colorama (from sacrebleu>=1.4.12->fairseq)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (4.9.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.12.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (2.1.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq) (2.21)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->fairseq) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->fairseq) (1.3.0)\n","Building wheels for collected packages: fairseq, antlr4-python3-runtime\n","  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=11289871 sha256=e3b8f8871650c2d9f6e3a8517cc960735b015e3810b8f344a6a630d6bd4fe983\n","  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141209 sha256=ab4e62242d6c7e0b0dc0576f0067614a9b0bec312f8545724b04436e32fb06c0\n","  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n","Successfully built fairseq antlr4-python3-runtime\n","Installing collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, colorama, sacrebleu, hydra-core, fairseq\n","Successfully installed antlr4-python3-runtime-4.8 bitarray-2.8.2 colorama-0.4.6 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.8.2 sacrebleu-2.3.1\n","Collecting fastBPE\n","  Downloading fastBPE-0.1.0.tar.gz (35 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: fastBPE\n","  Building wheel for fastBPE (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fastBPE: filename=fastBPE-0.1.0-cp310-cp310-linux_x86_64.whl size=806316 sha256=e857ec62cb1a29f991e88e9ca829ed755195fa462d4d379672cdf39e56ab9977\n","  Stored in directory: /root/.cache/pip/wheels/13/5d/b9/4b8897941ebc9e8c6cc3f3ffd3ea5115731754269205098754\n","Successfully built fastBPE\n","Installing collected packages: fastBPE\n","Successfully installed fastBPE-0.1.0\n"]}],"source":["!pip install transformers\n","!pip install fairseq\n","!pip install fastBPE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i5HZkAyUdFRt"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import time\n","import re\n","import random\n","import seaborn as sns\n","from tqdm.notebook import tqdm\n","import torch\n","import argparse\n","import pickle\n","import numpy as np\n","from os.path import join\n","import pandas as pd\n","\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import StepLR\n","from torch.autograd import Variable\n","from torch.backends import cudnn\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n","from sklearn.manifold import TSNE\n","\n","from fairseq.models.roberta import RobertaModel\n","from fairseq.data.encoders.fastbpe import fastBPE\n","from fairseq.data import Dictionary\n","from transformers.modeling_utils import *\n","from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule\n","from transformers import AutoModel, AutoTokenizer\n","\n","import argparse"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"okcCy-khEzhG"},"outputs":[],"source":["warmup_sets = '/content/drive/MyDrive/pRoBERTa/data/converted_data_warmup_tocken.json'\n","train_sets = '/content/drive/MyDrive/pRoBERTa/data/converted_data_warmup_tocken.json'\n","dest = '/content/drive/MyDrive/pRoBERTa/trained_module/rationale_selection'\n","model = 'base'\n","epochs = 20\n","batch_size_gpu = 4\n","batch_size_accumulated = 256\n","lr_base = 1e-5\n","lr_linear = 1e-3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1697907860036,"user":{"displayName":"Đức Bùi Duy Anh","userId":"13275453910777475613"},"user_tz":-420},"id":"uvyW0zjlFLg3","outputId":"52c9fb55-a968-4c28-cf68-88b4c77f709c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device \"cuda\"\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f'Using device \"{device}\"')"]},{"cell_type":"markdown","metadata":{"id":"9M2qzNQFFPXi"},"source":["# Load data"]},{"cell_type":"code","source":["import random\n","class LoadDataFromJson(Dataset):\n","    def __init__(self, datasets):\n","        self.samples = []\n","        with open(datasets) as file:\n","            data = json.load(file)\n","\n","        for id, item in data.items():\n","            sentences = item[\"context\"]\n","            if item[\"evidence\"] != None:\n","              for sentence in sentences:\n","                evidence = item['evidence'] in sentence\n","                if evidence:\n","                  data_sample = {}\n","                  data_sample['id'] = id\n","                  data_sample['claim'] = item['claim']\n","                  data_sample['sentence'] = sentence\n","                  data_sample['evidence'] = True\n","                  data_sample['domain'] = item['domain']\n","                  self.samples.append(data_sample)\n","            else:\n","              random_sentence = random.sample(sentences, 2)\n","              for sentence in random_sentence:\n","                data_sample = {}\n","                data_sample['id'] = id\n","                data_sample['claim'] = item['claim']\n","                data_sample['sentence'] = sentence\n","                data_sample['evidence'] = False\n","                data_sample['domain'] = item['domain']\n","                self.samples.append(data_sample)\n","\n","    def to_dataframe(self):\n","        return pd.DataFrame(self.samples)\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        return self.samples[idx]"],"metadata":{"id":"NYQ3kw75PH4i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = LoadDataFromJson(train_sets)\n","df_train = data_train.to_dataframe()"],"metadata":{"id":"RlI44bX6Q_2i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train"],"metadata":{"id":"TK879uu1Vd6W","executionInfo":{"status":"ok","timestamp":1697908005056,"user_tz":-420,"elapsed":355,"user":{"displayName":"Đức Bùi Duy Anh","userId":"13275453910777475613"}},"outputId":"03e84345-826d-46e3-ab89-f38476a86c25","colab":{"base_uri":"https://localhost:8080/","height":424}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         id                                              claim  \\\n","0     36112  trong năm nay hai địa_phương dẫn_đầu và gần nh...   \n","1     27839                            faa có hơn 10 nhân_viên   \n","2     27839                            faa có hơn 10 nhân_viên   \n","3     36633  do_đó chị đã quyết_định mở hàng ốc nhồi hơn mộ...   \n","4     18939  số người mắc_chứng tâm_lý ptsd tăng mạnh sau m...   \n","...     ...                                                ...   \n","1457  10840  gueorguiev được phép trò_chuyện với người khác...   \n","1458  15809  tỉnh gia_lai đã và đang huy_động người_dân cân...   \n","1459  15809  tỉnh gia_lai đã và đang huy_động người_dân cân...   \n","1460    881  em rất mơ_hồ về các mức lương trong ngành kinh_tế   \n","1461    881  em rất mơ_hồ về các mức lương trong ngành kinh_tế   \n","\n","                                               sentence  evidence   domain  \n","0     năm nay hai địa_phương có lượng hồ_sơ dẫn_đầu ...      True  khoahoc  \n","1     ngoài cuộc điều_tra của faa spacex cũng phải đ...     False  khoahoc  \n","2     cục hàng_không liên_bang mỹ ( faa ) đang giám_...     False  khoahoc  \n","3     vì_vậy sau khi trở_lại sài_gòn chị đã quyết_đị...      True   dulich  \n","4     hai người trong tiểu_đoàn của anh đã tự_sát từ...     False  thegioi  \n","...                                                 ...       ...      ...  \n","1457  gueorguiev được phép trò_chuyện với mọi người ...      True  thegioi  \n","1458  gia_đình ông bỏ khoảng 200 triệu đồng đầu_tư 4...     False   thoisu  \n","1459     năm 202023 toàn tỉnh gia_lai có trên 30 ha mía     False   thoisu  \n","1460                          em rất mơ_hồ về các ngành     False  giaoduc  \n","1461  tuy_nhiên em hiện chưa xác_định được hướng đi ...     False  giaoduc  \n","\n","[1462 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-67b18426-0418-437f-9f20-956064652ec0\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>claim</th>\n","      <th>sentence</th>\n","      <th>evidence</th>\n","      <th>domain</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>36112</td>\n","      <td>trong năm nay hai địa_phương dẫn_đầu và gần nh...</td>\n","      <td>năm nay hai địa_phương có lượng hồ_sơ dẫn_đầu ...</td>\n","      <td>True</td>\n","      <td>khoahoc</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>27839</td>\n","      <td>faa có hơn 10 nhân_viên</td>\n","      <td>ngoài cuộc điều_tra của faa spacex cũng phải đ...</td>\n","      <td>False</td>\n","      <td>khoahoc</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>27839</td>\n","      <td>faa có hơn 10 nhân_viên</td>\n","      <td>cục hàng_không liên_bang mỹ ( faa ) đang giám_...</td>\n","      <td>False</td>\n","      <td>khoahoc</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>36633</td>\n","      <td>do_đó chị đã quyết_định mở hàng ốc nhồi hơn mộ...</td>\n","      <td>vì_vậy sau khi trở_lại sài_gòn chị đã quyết_đị...</td>\n","      <td>True</td>\n","      <td>dulich</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>18939</td>\n","      <td>số người mắc_chứng tâm_lý ptsd tăng mạnh sau m...</td>\n","      <td>hai người trong tiểu_đoàn của anh đã tự_sát từ...</td>\n","      <td>False</td>\n","      <td>thegioi</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1457</th>\n","      <td>10840</td>\n","      <td>gueorguiev được phép trò_chuyện với người khác...</td>\n","      <td>gueorguiev được phép trò_chuyện với mọi người ...</td>\n","      <td>True</td>\n","      <td>thegioi</td>\n","    </tr>\n","    <tr>\n","      <th>1458</th>\n","      <td>15809</td>\n","      <td>tỉnh gia_lai đã và đang huy_động người_dân cân...</td>\n","      <td>gia_đình ông bỏ khoảng 200 triệu đồng đầu_tư 4...</td>\n","      <td>False</td>\n","      <td>thoisu</td>\n","    </tr>\n","    <tr>\n","      <th>1459</th>\n","      <td>15809</td>\n","      <td>tỉnh gia_lai đã và đang huy_động người_dân cân...</td>\n","      <td>năm 202023 toàn tỉnh gia_lai có trên 30 ha mía</td>\n","      <td>False</td>\n","      <td>thoisu</td>\n","    </tr>\n","    <tr>\n","      <th>1460</th>\n","      <td>881</td>\n","      <td>em rất mơ_hồ về các mức lương trong ngành kinh_tế</td>\n","      <td>em rất mơ_hồ về các ngành</td>\n","      <td>False</td>\n","      <td>giaoduc</td>\n","    </tr>\n","    <tr>\n","      <th>1461</th>\n","      <td>881</td>\n","      <td>em rất mơ_hồ về các mức lương trong ngành kinh_tế</td>\n","      <td>tuy_nhiên em hiện chưa xác_định được hướng đi ...</td>\n","      <td>False</td>\n","      <td>giaoduc</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1462 rows × 5 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67b18426-0418-437f-9f20-956064652ec0')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-67b18426-0418-437f-9f20-956064652ec0 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-67b18426-0418-437f-9f20-956064652ec0');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-dd3b3a03-425b-4fa1-aac5-af6c5d977fb4\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dd3b3a03-425b-4fa1-aac5-af6c5d977fb4')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-dd3b3a03-425b-4fa1-aac5-af6c5d977fb4 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["df_train['evidence'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IC-XzgZjXa_b","executionInfo":{"status":"ok","timestamp":1697908005810,"user_tz":-420,"elapsed":392,"user":{"displayName":"Đức Bùi Duy Anh","userId":"13275453910777475613"}},"outputId":"5309399c-14ae-458d-f680-860446540e2e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False    936\n","True     526\n","Name: evidence, dtype: int64"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# filtered_df = df_train.loc[(df_train['sentence'].apply(lambda x: len(x.split())) < 5) & (df_train['evidence'] == False)]\n","# filtered_df\n","# # Xóa những dòng có chiều dài sentence < 5 và evidence = 0\n","# df_train = df_train.drop(df_train[df_train.isin(filtered_df.to_dict('list')).all(1)].index)"],"metadata":{"id":"p9ELPNB3ZfRm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Xóa những dòng có chiều dài sentence < 5 và evidence = 0\n","# df_train = df_train.drop(df_train[df_train.isin(filtered_df.to_dict('list')).all(1)].index)"],"metadata":{"id":"wn5o_NpHZuLY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train = df_train.sample(frac=1, random_state=42)"],"metadata":{"id":"rD8In9JJeja3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"ad4O-fkbeojT","executionInfo":{"status":"ok","timestamp":1697908005811,"user_tz":-420,"elapsed":11,"user":{"displayName":"Đức Bùi Duy Anh","userId":"13275453910777475613"}},"outputId":"0abacf30-62cd-420d-a869-15734c6ecba7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         id                                              claim  \\\n","892   46877  đây là nơi thu_hút người không có tài_năng khô...   \n","1106   6561       vị ngọt từ hoa_quả có lợi hơn so với hóa học   \n","413   10577  ngày 16/1 khi công_bố kết_quả khám_nghiệm con ...   \n","522   10515  hành_vi ăn thịt đồng_loại của cá_sấu dao_động ...   \n","1036  47315  một điều thú_vị khác là những họ_hàng gần nhất...   \n","...     ...                                                ...   \n","1130  20038  tuyến phà gót cái viềng vẫn giữ giá vé không đ...   \n","1294  12395  kiều_bào ở cả châu_âu và nhật_bản đều có nhu_c...   \n","860   40689  sinh_viên không bị bảo_tàng leeum yêu_cầu phải...   \n","1459  15809  tỉnh gia_lai đã và đang huy_động người_dân cân...   \n","1126  11426          phẫu_thuật căng_da để lại sẹo ở vùng bụng   \n","\n","                                               sentence  evidence   domain  \n","892   đây là nơi thu_hút người tài có năng_lực hấp_t...      True  khoahoc  \n","1106  người_mẫu chia_sẻ việc bôi kem chống nắng trán...     False  suckhoe  \n","413   kết_quả khám_nghiệm được công_bố hôm 16/1 cho ...      True  khoahoc  \n","522   tuy_nhiên tần_suất xảy ra hành_vi này dao_động...      True  khoahoc  \n","1036  một điều thú_vị khác là những họ_hàng gần nhất...      True  khoahoc  \n","...                                                 ...       ...      ...  \n","1130  nếu đi từ tp hải_phòng người_dân và du_khách c...     False   dulich  \n","1294  trong chuyến làm_việc tới châu_âu mới_đây ông ...      True  thegioi  \n","860   bảo_tàng leeum quyết_định không yêu_cầu sinh_v...      True  thegioi  \n","1459     năm 202023 toàn tỉnh gia_lai có trên 30 ha mía     False   thoisu  \n","1126  tương_tự trường_hợp của chị thùy_linh cũng thự...      True  suckhoe  \n","\n","[1462 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-004fd730-daed-4f40-9bd4-35a3e032e586\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>claim</th>\n","      <th>sentence</th>\n","      <th>evidence</th>\n","      <th>domain</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>892</th>\n","      <td>46877</td>\n","      <td>đây là nơi thu_hút người không có tài_năng khô...</td>\n","      <td>đây là nơi thu_hút người tài có năng_lực hấp_t...</td>\n","      <td>True</td>\n","      <td>khoahoc</td>\n","    </tr>\n","    <tr>\n","      <th>1106</th>\n","      <td>6561</td>\n","      <td>vị ngọt từ hoa_quả có lợi hơn so với hóa học</td>\n","      <td>người_mẫu chia_sẻ việc bôi kem chống nắng trán...</td>\n","      <td>False</td>\n","      <td>suckhoe</td>\n","    </tr>\n","    <tr>\n","      <th>413</th>\n","      <td>10577</td>\n","      <td>ngày 16/1 khi công_bố kết_quả khám_nghiệm con ...</td>\n","      <td>kết_quả khám_nghiệm được công_bố hôm 16/1 cho ...</td>\n","      <td>True</td>\n","      <td>khoahoc</td>\n","    </tr>\n","    <tr>\n","      <th>522</th>\n","      <td>10515</td>\n","      <td>hành_vi ăn thịt đồng_loại của cá_sấu dao_động ...</td>\n","      <td>tuy_nhiên tần_suất xảy ra hành_vi này dao_động...</td>\n","      <td>True</td>\n","      <td>khoahoc</td>\n","    </tr>\n","    <tr>\n","      <th>1036</th>\n","      <td>47315</td>\n","      <td>một điều thú_vị khác là những họ_hàng gần nhất...</td>\n","      <td>một điều thú_vị khác là những họ_hàng gần nhất...</td>\n","      <td>True</td>\n","      <td>khoahoc</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1130</th>\n","      <td>20038</td>\n","      <td>tuyến phà gót cái viềng vẫn giữ giá vé không đ...</td>\n","      <td>nếu đi từ tp hải_phòng người_dân và du_khách c...</td>\n","      <td>False</td>\n","      <td>dulich</td>\n","    </tr>\n","    <tr>\n","      <th>1294</th>\n","      <td>12395</td>\n","      <td>kiều_bào ở cả châu_âu và nhật_bản đều có nhu_c...</td>\n","      <td>trong chuyến làm_việc tới châu_âu mới_đây ông ...</td>\n","      <td>True</td>\n","      <td>thegioi</td>\n","    </tr>\n","    <tr>\n","      <th>860</th>\n","      <td>40689</td>\n","      <td>sinh_viên không bị bảo_tàng leeum yêu_cầu phải...</td>\n","      <td>bảo_tàng leeum quyết_định không yêu_cầu sinh_v...</td>\n","      <td>True</td>\n","      <td>thegioi</td>\n","    </tr>\n","    <tr>\n","      <th>1459</th>\n","      <td>15809</td>\n","      <td>tỉnh gia_lai đã và đang huy_động người_dân cân...</td>\n","      <td>năm 202023 toàn tỉnh gia_lai có trên 30 ha mía</td>\n","      <td>False</td>\n","      <td>thoisu</td>\n","    </tr>\n","    <tr>\n","      <th>1126</th>\n","      <td>11426</td>\n","      <td>phẫu_thuật căng_da để lại sẹo ở vùng bụng</td>\n","      <td>tương_tự trường_hợp của chị thùy_linh cũng thự...</td>\n","      <td>True</td>\n","      <td>suckhoe</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1462 rows × 5 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-004fd730-daed-4f40-9bd4-35a3e032e586')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-004fd730-daed-4f40-9bd4-35a3e032e586 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-004fd730-daed-4f40-9bd4-35a3e032e586');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-2094ef7a-6920-408c-803b-25604dd7bc9c\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2094ef7a-6920-408c-803b-25604dd7bc9c')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-2094ef7a-6920-408c-803b-25604dd7bc9c button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["w = df_train.loc[df_train['id'] == \"46576\"].sentence\n","w"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxenBWn7gOb4","executionInfo":{"status":"ok","timestamp":1697908005811,"user_tz":-420,"elapsed":10,"user":{"displayName":"Đức Bùi Duy Anh","userId":"13275453910777475613"}},"outputId":"35c43914-d9e7-48b3-b596-2c98005c99fa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Series([], Name: sentence, dtype: object)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["a = df_train[df_train['evidence'] == True]\n","a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"QJmF0KBZpM2-","executionInfo":{"status":"ok","timestamp":1697908005811,"user_tz":-420,"elapsed":9,"user":{"displayName":"Đức Bùi Duy Anh","userId":"13275453910777475613"}},"outputId":"57bcf6f5-67bb-42b0-c2ff-9b47cd12e123"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         id                                              claim  \\\n","892   46877  đây là nơi thu_hút người không có tài_năng khô...   \n","413   10577  ngày 16/1 khi công_bố kết_quả khám_nghiệm con ...   \n","522   10515  hành_vi ăn thịt đồng_loại của cá_sấu dao_động ...   \n","1036  47315  một điều thú_vị khác là những họ_hàng gần nhất...   \n","1161  11066  nam_giới cần tiêm xuất_tinh tối_đa 7 ngày trướ...   \n","...     ...                                                ...   \n","1123  13992  người nông_dân dễ_dàng tìm_kiếm các loại thuốc...   \n","330    7210  ngoài việc khám_phá vùng_đất mới để học cách s...   \n","1294  12395  kiều_bào ở cả châu_âu và nhật_bản đều có nhu_c...   \n","860   40689  sinh_viên không bị bảo_tàng leeum yêu_cầu phải...   \n","1126  11426          phẫu_thuật căng_da để lại sẹo ở vùng bụng   \n","\n","                                               sentence  evidence   domain  \n","892   đây là nơi thu_hút người tài có năng_lực hấp_t...      True  khoahoc  \n","413   kết_quả khám_nghiệm được công_bố hôm 16/1 cho ...      True  khoahoc  \n","522   tuy_nhiên tần_suất xảy ra hành_vi này dao_động...      True  khoahoc  \n","1036  một điều thú_vị khác là những họ_hàng gần nhất...      True  khoahoc  \n","1161  trước khi làm xét_nghiệm nam_giới cần kiêng xu...      True  suckhoe  \n","...                                                 ...       ...      ...  \n","1123  vì_vậy phần_mềm_tra cứu thuốc trên điện_thoại ...      True   thoisu  \n","330   song_song quá_trình cùng học_tập rèn_luyện kỹ_...      True  giaoduc  \n","1294  trong chuyến làm_việc tới châu_âu mới_đây ông ...      True  thegioi  \n","860   bảo_tàng leeum quyết_định không yêu_cầu sinh_v...      True  thegioi  \n","1126  tương_tự trường_hợp của chị thùy_linh cũng thự...      True  suckhoe  \n","\n","[526 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-44380267-7e3d-4c28-8c4b-bdadad734845\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>claim</th>\n","      <th>sentence</th>\n","      <th>evidence</th>\n","      <th>domain</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>892</th>\n","      <td>46877</td>\n","      <td>đây là nơi thu_hút người không có tài_năng khô...</td>\n","      <td>đây là nơi thu_hút người tài có năng_lực hấp_t...</td>\n","      <td>True</td>\n","      <td>khoahoc</td>\n","    </tr>\n","    <tr>\n","      <th>413</th>\n","      <td>10577</td>\n","      <td>ngày 16/1 khi công_bố kết_quả khám_nghiệm con ...</td>\n","      <td>kết_quả khám_nghiệm được công_bố hôm 16/1 cho ...</td>\n","      <td>True</td>\n","      <td>khoahoc</td>\n","    </tr>\n","    <tr>\n","      <th>522</th>\n","      <td>10515</td>\n","      <td>hành_vi ăn thịt đồng_loại của cá_sấu dao_động ...</td>\n","      <td>tuy_nhiên tần_suất xảy ra hành_vi này dao_động...</td>\n","      <td>True</td>\n","      <td>khoahoc</td>\n","    </tr>\n","    <tr>\n","      <th>1036</th>\n","      <td>47315</td>\n","      <td>một điều thú_vị khác là những họ_hàng gần nhất...</td>\n","      <td>một điều thú_vị khác là những họ_hàng gần nhất...</td>\n","      <td>True</td>\n","      <td>khoahoc</td>\n","    </tr>\n","    <tr>\n","      <th>1161</th>\n","      <td>11066</td>\n","      <td>nam_giới cần tiêm xuất_tinh tối_đa 7 ngày trướ...</td>\n","      <td>trước khi làm xét_nghiệm nam_giới cần kiêng xu...</td>\n","      <td>True</td>\n","      <td>suckhoe</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1123</th>\n","      <td>13992</td>\n","      <td>người nông_dân dễ_dàng tìm_kiếm các loại thuốc...</td>\n","      <td>vì_vậy phần_mềm_tra cứu thuốc trên điện_thoại ...</td>\n","      <td>True</td>\n","      <td>thoisu</td>\n","    </tr>\n","    <tr>\n","      <th>330</th>\n","      <td>7210</td>\n","      <td>ngoài việc khám_phá vùng_đất mới để học cách s...</td>\n","      <td>song_song quá_trình cùng học_tập rèn_luyện kỹ_...</td>\n","      <td>True</td>\n","      <td>giaoduc</td>\n","    </tr>\n","    <tr>\n","      <th>1294</th>\n","      <td>12395</td>\n","      <td>kiều_bào ở cả châu_âu và nhật_bản đều có nhu_c...</td>\n","      <td>trong chuyến làm_việc tới châu_âu mới_đây ông ...</td>\n","      <td>True</td>\n","      <td>thegioi</td>\n","    </tr>\n","    <tr>\n","      <th>860</th>\n","      <td>40689</td>\n","      <td>sinh_viên không bị bảo_tàng leeum yêu_cầu phải...</td>\n","      <td>bảo_tàng leeum quyết_định không yêu_cầu sinh_v...</td>\n","      <td>True</td>\n","      <td>thegioi</td>\n","    </tr>\n","    <tr>\n","      <th>1126</th>\n","      <td>11426</td>\n","      <td>phẫu_thuật căng_da để lại sẹo ở vùng bụng</td>\n","      <td>tương_tự trường_hợp của chị thùy_linh cũng thự...</td>\n","      <td>True</td>\n","      <td>suckhoe</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>526 rows × 5 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44380267-7e3d-4c28-8c4b-bdadad734845')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-44380267-7e3d-4c28-8c4b-bdadad734845 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-44380267-7e3d-4c28-8c4b-bdadad734845');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-693c84ac-01da-4b1c-8a28-0b17ec1d0124\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-693c84ac-01da-4b1c-8a28-0b17ec1d0124')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-693c84ac-01da-4b1c-8a28-0b17ec1d0124 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# data_val = LoadDataFromJson(warmup_sets)\n","# df_val = data_val.to_dataframe()\n","# df_val = df_val.sample(frac=1, random_state=42)"],"metadata":{"id":"sODbqQ6fRSGw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# df_val"],"metadata":{"id":"68ntJN0oY7qL"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tMDVZARIjJuX"},"outputs":[],"source":["# df_train.to_json('/content/drive/MyDrive/pRoBERTa/data/df_train_rationale_selection.json')"]},{"cell_type":"code","source":["df_train = df_train.head(100)"],"metadata":{"id":"NcPYp8AZLO80"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UTswZ3MTjGSd"},"source":["# Chuẩn bị dữ liệu train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZD0l0QVjFgSW","colab":{"base_uri":"https://localhost:8080/","height":177,"referenced_widgets":["9e741afade0c43bea535ab16c233b455","863267402a304dfe94bd6606692313a1","7ea0f6eb588d43f2b2b37de24063daec","5c94014fceea46eaa6be4bf281b790aa","22878c0b240e4dae9ce0e7ddc4d25990","056ffb966c154cffaf93817aff2b72c5","68491a2219a244eab2999bfe2e4750fc","d793fcbf8210455883c82399c2fcfbca","3992630bbd9042098dc8e24d2939346c","eaa925f268ef4e03812c8f1b86ef181a","901fbec481c841698cb7d087d087296a","aab96a30a8824fdc98937d8f39811b59","3303595a38384063887575352d77e485","a7c7b2f13e7a49ccac298e0f3d61fe41","d82f5ce0e6c844ef969c37a7038fe81e","cbe1094dc04140a9872b45813e65ca38","90d9cfbb92be40ca96087c1312df5b69","274466cb93cb4eab92351af04ea00f62","aa7a49cc8a0a4726b3051fe08be93c85","f482c215e806426abcd9e6cacd01f7b4","eda883c9b6954489a112e3e1e739dbb4","8ba87271333e41d7b000d8914f3e9590","7063d9a90d0f43589ba96604fad38c50","44df77f99dbb49e894580165657dcf2b","0b912422cf96432c9cd5d4094b45f674","7bf340da7a2f42ce93366bffaaedaf4d","42f93dd648dd4adfad5331568c1bd467","8fc4958d31844f518edbd70786e1e92e","4278a0e3a11142deaa955c74dcf6614d","549b0ce8164d432ebb45cad5ca1c67e6","dcf6df4b531c41238cb82c673a9ceea2","47a6ed8a543a47a699a7e181c1239e58","c6a2164e8d0b4feeb4107c4cbe513395","72a4db38da374937ada94ddd84fe9bf2","4cb66dbb59154c218605854f672e5342","0e8726dfb41645038a4217950ad70718","9bd0bd2b4a2245679604966630be1442","85566a0c4b0e46c7a9e36b0cb712b16b","eed77b2e3a1140aa8c6e47a003d03d05","2b28c08a5ffa4383b6035410101cd0be","84e11e3cc864405abd6c2c2ea3d7cce6","969df808011545b08f342375351ea9dc","48622611962c4ed6a1a72466ec887a27","3549e084e2ef4b78b7e2c0c2cf0b66df","d0129ddcb6a3414cbf86b6546f085efb","c7a55b3bef7d44e38cb3a667626232c1","cc32f484bb1e40c1b1fd3aef495ade44","4f92b7bcc97f4109a0e57e674f308f47","b699c1d8376a40f7859867a362fecc1c","c6dcc83daf8140ff950e097ff0b941f2","59d5c5ef4e9341799501e43bd88c0aa2","7807ea36441a4c27a65d685807f1d02b","18434f6fce304203bb83a8510b04a05a","9180acf7335c4427a884021c50ce0725","0dd2f780c7e74e3bbf21864b6e900b7b"]},"executionInfo":{"status":"ok","timestamp":1697908021089,"user_tz":-420,"elapsed":15285,"user":{"displayName":"Đức Bùi Duy Anh","userId":"13275453910777475613"}},"outputId":"5e1f2ce2-6a60-4857-818c-53a426bb5f8c"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/557 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e741afade0c43bea535ab16c233b455"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/543M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aab96a30a8824fdc98937d8f39811b59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7063d9a90d0f43589ba96604fad38c50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72a4db38da374937ada94ddd84fe9bf2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/3.13M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0129ddcb6a3414cbf86b6546f085efb"}},"metadata":{}}],"source":["# load model phoBert và tokenizer của model đó\n","model_bert = AutoModel.from_pretrained(f'vinai/phobert-{model}').to(device).eval()\n","tokenizer = AutoTokenizer.from_pretrained(f\"vinai/phobert-{model}\", use_fast=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"puHeu4U3Fz6N"},"outputs":[],"source":["# Load BPE encoder\n","parser = argparse.ArgumentParser()\n","parser.add_argument(\n","    '--bpe-codes',\n","    default=f'/content/drive/MyDrive/pRoBERTa/PhoBERT_{model}_transformers/bpe.codes',\n","    required=False,\n","    type=str,\n","    help='path to fastBPE BPE'\n",")\n","\n","args, unknown = parser.parse_known_args()\n","bpe = fastBPE(args)\n","\n","# Load the dictionary\n","vocab = Dictionary()\n","vocab.add_from_file(f'/content/drive/MyDrive/pRoBERTa/PhoBERT_{model}_transformers/dict.txt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IwTuE_4jGoWd"},"outputs":[],"source":["input_sent = df_train.loc[:, ['claim','sentence']]\n","input_labels = df_train['evidence']"]},{"cell_type":"code","source":["# encode label\n","le = LabelEncoder()\n","train_labels = le.fit_transform(input_labels)\n","print(le.classes_)"],"metadata":{"id":"IYe5yg_S5f4Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697908128875,"user_tz":-420,"elapsed":600,"user":{"displayName":"Đức Bùi Duy Anh","userId":"13275453910777475613"}},"outputId":"904c6e75-f43f-4084-c4de-11faf4f52a2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[False  True]\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","train_sents, val_sents, train_labels, val_labels = train_test_split(input_sent, train_labels, test_size=0.1, random_state=42)"],"metadata":{"id":"KXJdrzsY5ahL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# val_sents = df_val.loc[:, ['claim','sentence']]\n","# val_labels = df_val['evidence']"],"metadata":{"id":"yHqj1ks0RgI-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NAX_yBvNGLG3"},"outputs":[],"source":["# # encode label\n","# le = LabelEncoder()\n","# train_labels = le.fit_transform(train_labels)\n","# print(le.classes_)\n","# val_labels = le.fit_transform(val_labels)\n","# print(le.classes_)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":118,"referenced_widgets":["36d9242d689248b0b33d850078a2ff7e","3fbcb080318748ca9747a83bdfa86c00","bb806c3ca77b43dca5ccef3579321537","ea39247f29704e93b981be6ecb4e1bff","7e22faacd15e4bbc9e6c38698b33d92d","d550d5086b654fc2a54e68e06cadb4b1","bde4728b052d461eba75f74f07cd1d40","63f3eee8ad5440c6a9bde03a355ab638","1bb4b45e43a5411e9a4edb74cdcef108","f8dc2095d91b4502816326bb7956d753","28d5af24ff424b52a7e24d338a81a03c","8cd56df5bbca4c50ad2203ef8b708372","308da933bf6a4a3a8bed558dfc4fcfea","4942b37ff1c642daa39b68616605bdb1","cf7cf0b2c11e4fff8284c439fc026ae2","e913e0070fb14628acb31d4a36d467d0","a31ca005a3dd493abd097df0d54fd9c2","83db8529a856485e9a5e20ecc41bdeac","4087fa3431ef47258bb0bdb5d0b156ef","95389e8c32b14c8cb323a5ba02bdb799","969621ba6ecc402e94344b44ee7a0798","a45f5fd64bcb45acb16dfd4f6fd76a61"]},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1697908128876,"user":{"displayName":"Đức Bùi Duy Anh","userId":"13275453910777475613"},"user_tz":-420},"id":"t_LshuoCG1uL","outputId":"e8fdfa02-1897-4c35-e457-9fba7af61fce"},"outputs":[{"output_type":"stream","name":"stdout","text":["Processing train set ...\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36d9242d689248b0b33d850078a2ff7e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing test set ...\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cd56df5bbca4c50ad2203ef8b708372"}},"metadata":{}}],"source":["# Thực hiện chuyển dataset ban đầu thành subword index\n","MAX_LEN = 256\n","\n","train_ids = []\n","print('Processing train set ...')\n","for index, row in tqdm(train_sents.iterrows()):\n","  claim_value = row['claim']\n","  sentence_value = row['sentence']\n","  subwords = '[CLS]' + bpe.encode(claim_value) + '[SEP]' + bpe.encode(sentence_value) + '[SEP]'\n","  encoded_sent = vocab.encode_line(subwords, append_eos=True, add_if_not_exist=False).long()\n","  train_ids.append(encoded_sent)\n","\n","val_ids = []\n","print('Processing test set ...')\n","for index, row in tqdm(val_sents.iterrows()):\n","  claim_value = row['claim']\n","  sentence_value = row['sentence']\n","  subwords = '[CLS]' + bpe.encode(claim_value) + '[SEP]' + bpe.encode(sentence_value) + '[SEP]'\n","  encoded_sent = vocab.encode_line(subwords, append_eos=True, add_if_not_exist=False).long()\n","  val_ids.append(encoded_sent)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yDdS2SOnHBND"},"outputs":[],"source":["# thêm padding\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","train_ids = pad_sequences(train_ids, maxlen=MAX_LEN, dtype='long', value=1, truncating='post', padding='post')\n","val_ids = pad_sequences(val_ids, maxlen=MAX_LEN, dtype='long', value=1, truncating='post', padding='post')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tR6s6w02HEBF"},"outputs":[],"source":["# Tạo mask để BERT không chú ý tới padding (pad id = 1)\n","train_masks = []\n","for sent in train_ids:\n","  mask = [int(token_id != 1) for token_id in sent]\n","  train_masks.append(mask)\n","\n","val_masks = []\n","for sent in val_ids:\n","  mask = [int(token_id != 1) for token_id in sent]\n","  val_masks.append(mask)"]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","BATCH_SIZE = 16\n","\n","# convert sang tensor\n","train_inputs = torch.tensor(train_ids)\n","val_inputs = torch.tensor(val_ids)\n","\n","train_labels = torch.tensor(train_labels)\n","val_labels = torch.tensor(val_labels)\n","\n","train_masks = torch.tensor(train_masks)\n","val_masks = torch.tensor(val_masks)"],"metadata":{"id":"SIvei6KNf33Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CRjmdtyZHF8x"},"outputs":[],"source":["# tạo data loader để train\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = SequentialSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n","\n","val_data = TensorDataset(val_inputs, val_masks, val_labels)\n","val_sampler = SequentialSampler(val_data)\n","val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=BATCH_SIZE)"]},{"cell_type":"markdown","metadata":{"id":"YLX9OPaUYzlt"},"source":["\n","# Xây dựng model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10353,"status":"ok","timestamp":1697908139221,"user":{"displayName":"Đức Bùi Duy Anh","userId":"13275453910777475613"},"user_tz":-420},"id":"wK8DTdxyHIXa","outputId":"4f17822e-c2d4-43c1-be1c-3744f003b9f2"},"outputs":[{"output_type":"stream","name":"stderr","text":["You are using a model of type bert to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/pRoBERTa/PhoBERT_base_transformers/model.bin and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import RobertaForSequenceClassification, RobertaConfig, AdamW\n","\n","NUM_CLASSES = 2\n","\n","# load file config\n","config = RobertaConfig.from_pretrained(\n","    f'/content/drive/MyDrive/pRoBERTa/PhoBERT_{model}_transformers/config.json',\n","    from_tf=False,\n","    num_labels=NUM_CLASSES,\n","    output_hidden_states=False\n",")\n","\n","# load model\n","BERT_SA = RobertaForSequenceClassification.from_pretrained(\n","    f'/content/drive/MyDrive/pRoBERTa/PhoBERT_{model}_transformers/model.bin',\n","    config=config\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1697908139221,"user":{"displayName":"Đức Bùi Duy Anh","userId":"13275453910777475613"},"user_tz":-420},"id":"NN0nITokfRer","outputId":"4286704b-4b32-40ba-cf12-205f920830f6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["RobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(64001, 768, padding_idx=0)\n","      (position_embeddings): Embedding(258, 768, padding_idx=0)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":46}],"source":["BERT_SA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yewWL3VM2dFU"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from transformers import RobertaModel\n","\n","class CustomRobertaClassificationHead(nn.Module):\n","    def __init__(self, hidden_size, num_labels):\n","        super(CustomRobertaClassificationHead, self).__init__()\n","        self.dense = nn.Linear(768, 768)\n","        self.dropout = nn.Dropout(p=0.1)\n","        self.lstm = nn.LSTM(input_size=hidden_size, hidden_size=256, batch_first=True)\n","        self.fc1 = nn.Linear(256, 128)\n","        self.out_proj = nn.Linear(128, num_labels)\n","\n","    def forward(self, hidden_states):\n","        x = self.dense(hidden_states)  # Ánh xạ hidden_states qua lớp tuyến tính dense\n","        x = torch.relu(x)  # Áp dụng hàm kích hoạt ReLU\n","        x = self.dropout(x)  # Áp dụng dropout\n","        _, (h_n, _) = self.lstm(x)  # Đưa x qua LSTM và lấy hidden state cuối cùng\n","        x = self.fc1(h_n[-1])\n","        x = self.out_proj(x)\n","\n","        return x\n","\n","class CustomRobertaForSequenceClassification(nn.Module):\n","    def __init__(self, model, num_labels):\n","        super(CustomRobertaForSequenceClassification, self).__init__()\n","\n","        self.roberta = model\n","        self.roberta.classifier = CustomRobertaClassificationHead(hidden_size=768, num_labels=num_labels)\n","\n","    def forward(self, input_ids = None, token_type_ids = None, attention_mask = None, labels = None):\n","        outputs = self.roberta(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask, labels=labels)\n","        return outputs\n","\n","    def save_pretrained(self, PATH):\n","       # Create the directory if it doesn't exist\n","      os.makedirs(PATH, exist_ok=True)\n","\n","      # Save the model's state_dict to a file\n","      model_path = os.path.join(PATH, 'model.bin')\n","      torch.save(self.state_dict(), model_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ExdS0WNN2xDU"},"outputs":[],"source":["custom_model = CustomRobertaForSequenceClassification(BERT_SA, 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cZWRpFq9HYGE"},"outputs":[],"source":["# Hàm đánh giá độ chính xác\n","def flat_accuracy(preds, labels):\n","  pred_flat = np.argmax(preds, axis=1).flatten()\n","  labels_flat = labels.flatten()\n","\n","  F1_score = f1_score(pred_flat, labels_flat, average='macro')\n","\n","  return accuracy_score(pred_flat, labels_flat), F1_score"]},{"cell_type":"markdown","metadata":{"id":"RxalBslqjvUK"},"source":["# Train model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3069,"status":"ok","timestamp":1697908142279,"user":{"displayName":"Đức Bùi Duy Anh","userId":"13275453910777475613"},"user_tz":-420},"id":"D8en7JmqKuYI","outputId":"c7ce5619-08bb-435a-dc7e-e611beffd950"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["CustomRobertaForSequenceClassification(\n","  (roberta): RobertaForSequenceClassification(\n","    (roberta): RobertaModel(\n","      (embeddings): RobertaEmbeddings(\n","        (word_embeddings): Embedding(64001, 768, padding_idx=0)\n","        (position_embeddings): Embedding(258, 768, padding_idx=0)\n","        (token_type_embeddings): Embedding(1, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): RobertaEncoder(\n","        (layer): ModuleList(\n","          (0-11): 12 x RobertaLayer(\n","            (attention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): RobertaIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): RobertaOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (classifier): CustomRobertaClassificationHead(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","      (lstm): LSTM(768, 256, batch_first=True)\n","      (fc1): Linear(in_features=256, out_features=128, bias=True)\n","      (out_proj): Linear(in_features=128, out_features=2, bias=True)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":50}],"source":["custom_model.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["dd6531eea552430bbe5257b0aab09f66","c59f9cbc7dc94e5b9d88752c64dc20c6","5c0477d5f5bf405a871ff201a93fa591","cf1c1bf844894bffb9b0c1421620c7b9","80cd583431e04bf2b3526f75dc04b313","b25f4498b9064175aa9e01b3e20790cd","27f67f25560d433281b9de72e6216bc3","28c9376680b54fc795a3aea180081551","9e22f89e182c45c7b94ad14870ecdf39","bb0000bfa148475b80a8d01a22ac08b0","420391808246407eae87f8739496791d","fa615f53008a42d188734530fa2b7c23","bdaca6711aa24d24abf921f25fddb919","e0179dc91ffc44e198d39b353547e76a","4d918a9bb7b24196a3a176be760df7a1","de77b66d31174d47b68c11aad11393ab","cdc0fd12d9cd41d294497f68d05e1d85","d10c371c37034ccd9215b4e9bda73640","d1c8f679d5534252995fca479a02dae1","e4a66d497ad44f958c3e7dd9d2102df4","fd8c4909018b4fa7b0ce016f3e24e66e","f89dc380b62d44c28e965661881bd194","fe97f5ea3dc3428d9724b448dd0a8cb4","81f5cafccc334fc4afd007c913829529","517e25070ca74d6e89120ce41ed56c58","651fe9b779b24dd187a02140b7ea9645","431bf69d3d1c4372b1f56e9ec38f487f","fa00c48fa3fc447eb24a79823eb08afc","2d2a66492f1d4d08909e9adaf638c9c3","14cfc430df2b4f7dbcc3d2c62ed030e8","48e5cca952b848249d923a9010c86f05","213c043fbbd3499895050987d948e21d","c73a6223bf2e404f85f95d73036bfa29","d11d8eb79e5e4bd78e1b68bdbdb61ad5","9c4ab26d9218466d972eebb6952e07c0","f4a1be0092cf422aaab8242e56bae167","aa503debe10546fa97acd842cd7ed301","8ebe6b0ebd3b4da486c9e65dda6e781b","6fa2e602263c470192429f73decf9b26","a9211bdd48f54f21b134e63696de6566","2a41ac9e36514a0abdc73449403c078a","2b36d5db6cd641a48a1cfff73acba508","4eb39b3f270f44ff94af0ece36ea5fd9","fa9846c4975f4775ba79e664a60eaeea","aa0e20b020ff4db4aea99e927b8d107f","6e4bf2c21d634347ad5ea320fb480e82","2a9371ee5b6d4daa80c0d238e6f5f5ef","77132e3b8b744490bda812df63923a8e","1299ea8d8fbd4721b625837ac5667584","5b685808635e429a8fbc72edad3bf1bd","fbfb09edc6744e63b892d6aea8dd1199","dadd3bf8ec7f42da80d2e299d030d690","648e5520e2b54c1faaccc4ecec88c8e9","08f94daf3a78404c977b7ba44f678e44","c319b075a2714a1ebe198933a999daee","0323a38c89144b408ef401b736f26837","f49d5535e35f47f4a656a38901be7510","108a96e56f514957850c3f7a0b4a2821","9b214291bf3041adac5f91e8d87fa846","2998081f536f44ac913d62f48c7d88d8","8870577f132b476eb414c1ffd9bcbfce","b0f43aaf814b4c26a79469a3a742f57d","8816ab646adf42d7b574bb97872a1db8","637a1a4fd2f24858b7702b406142017f","7f9e2fdbdcbe43558b6088176cbb0a01","8bfc211c431a4551a59d21fa064e09eb","014217f6e5b24a338054c3ffb990f31f","9555e1a6212942ea97f504c141ca7459","6432ae4447c84e69b230d8392a58f874","58d5bdfd7bcd411aa4e12fed40cdd021","8335648ae8e54a338c7bdd59e6fd4edd","058eeeadf5a643558348c0e8d790e959","bd41846a42d54b85aaf08975636ec827","02e8d2345e6a4df8a924cc9e5548d17b","d2c37b295b564d419f8ba07fa38e532b","9e4df21367c048f08e64a8af64833dba","faa133764afe42a69bb8fd38e57e9246","f342c14a6f804e6f932f6a942bc2727e","a291af9479cc441ba03bce9dea2c9de0","f5c3965f2f0f4bd1845da3d6f58d0f05","b7b2b3eebdb145109279dfb6c6a7d9d8","a7540caad920434a89ea4545a958486e","607f9d2a5e374463ad8d5f2991c2da35","ea24e3093fcd4b7ab568f85f9f70e70c","4f9bec4bae084b8d8613f3da6a4a67fa","88fb58dae49d4ecf8dda0a6d4c63f6d9","b26c810844e04871981bc3bc45caedc8","bc0c173327c54ee0988618c8523dc68a","e4fcd7bea02d4d93ae344215eb243e58","3fdd5a57c96f43648356418c41a0bd62","a278e4f050af4bcdb1f71280f8a2eff7","c56a111efa844052801ee11e83585047","8f133f1d41cd4adf90ad433b57081cbe","276a589015c14e4a84f74c1c27e4957a","5272ed0b03fb43efa529256e99fdd1ed","24d53ff7d7724d43ae4ba4e4129fc710","b82b8cf939674ac7bb03923cb2dd2e32","7a18de690a91416ba5989027ad04c2d5","d82bfafbc533401ea968c14d53244ef4","9ef0d057a69c455bb7e097fa12733d73","0d6920031e524ede83b04cc15a8bd7b3","e9639de6b5eb47cdb5f5e716462faa5c","7633b2ef1d4e46b080b06db58a60972a","85cd89e62be247cea4ff70fea90f2aac","0f5324eff9d44d8eba0fdda395c4e85d","afd9bf03efb54313a053fdb9a794a14b","6e9d0836d5f048959239197721d79238","510270b697894664a1efbc7297f3ca03","036af65e44f748279ea5b99c181e32ee","02e322a6436c480a9cb7e702d9336003","a6fedbbb1c254d26a7949a0b8ffbf61f","85edbb2b15c34881a895278c845894e4","19e7cd7da791435aae99ff7099ecb587","5ac26170c167439b8019c94d28b854b3","acb99102e6914589aa6ea5526e1954a4","19b33acb0c83473584bca3f15ac1f489","1b208b8ccb6e4687885bda7ba32c52d3","d026fe664c5e440a92de524ce9d531c7","9e18ffe12fe8432aadef7bf0817bbfbb","8c5e644c88bf4192b2951276959f7412","b48e2d39215344c5a76ce86bc540dbf9","89827b2bbb6f439f8884f1db8fb7f92e","11b5ba2e4e014a20b2c467d95602a7ff","8dfb70c141744bb384191efc91a768e6","b8bde0a15a1e4b4ab399304ad2e447f1","a13e71f5779044be88a1620f69280df4","c365b12ed9b14d1ebfb4a1ada74f000b","c15ea76ef8664ce89980e621800965b5","6a21d3228a4c43408a57a9fa888c4b46","3ef87761e2834e64867a127bda9edd75","1c8a772b52a64aaaacc7db3292361b97","7dfd88cff15448c69d5044c1386d23e7","ebde6c17a099484eb818784fe058e68d","4ceafd786ea64e3595352b9e4133060a","fd95286255ec4e96898101e9f3a30c57","4672525323124b2f8bb494dc76acc91e","f1f18a7255e646de9f9ba618965a26a6","f276c4c0abbb42a8b813055d9bd8bf1f","0404907a0b47496c895976a20a431e71","92863eab38b74c9abdf8fb2b76a68028","667ec4221ede4f0f92c36f598b77f40e","b522b749102a4d2cbbad7b6168b5a455","c9b2d32786514b2cb183dd0026157f76","b9dc9efa2fa04bd6a18c81ea56a25471","1e7b089cb05849f1b9bf6ae267bf51ea","4442610115ea476281e3b869f4c81416","ff518d1b2cfa47429a05ca23f839f9ca","61552b59a0a2463ebad9ca3220b6336e","c005427ad1fc40699f59ad9502ab8b65","e69497161b384344b4f72e60fd961ddf","7d086a200f0247edac81d7a7bda2f108","2cfa612828fd4139aa00d877f72e2212","c2c3e12a859b4db68c9153b2c63c1e51","13d9207cee2846009094efbd7d29abe7","f886ec0dbaa0410ab78be1f545b2bd9a","38b0b968e1b44743bc388c79f9e3b648","a295f696e8ee4018bdbd7226b47243f2","79bec756170845978be6ed55be9bfe65","c57e7e9eba7f4ed1b306b137ec32b183","00815f55dd7c43f78722b4d866a127a2","3142e6ab1b0b46d793dc0a022413a302","c9b9eb130b7d462d84ac25d5fe3028b2","a4c2eb6bd2dd481bad5baf173d313e02","259310844b3f4b31a41cc86a6114b261","15aa6e2e3c414cd39bcd53c28479bb9f","03c310a76f2e4cd29faceb3e5212466e","4b8350107a3c4c8cab310a6bdaa39c87","0455335ce2c04c93a558496af2044121","56bdac6382954406be1faa61adc38618","d189a0e025774675b1cca6fde427a884","3f09f95783b4478caffbf6b496893779","310874658cd64941a9e6e3e1d9d14fe5","f2bc632af0934239a264f0508c81243a","2448522aec6e4906b8ac4cb4ce3f5aee","afa6f9d0205148aa9a1914b58976eb32","8dd7f83b8e2a4069b524e011917a6e4c","d5f19f16c2f4411a9a69b898598cee3f","93aa4a3b9424498989d6a5e5c6ada64f","a4998f5ab946427b9ed75f4507e3df2b","621c9d48afff49a58700ccaefd84f4c4","e22ebf95623c47b5b334c91f6ed9a544","c3a2de64c88a4f16a0bc4088880a6fc9","c54a527c9c2c483485b0b87815068995","171f511b77e944d2a7fe9eef72aa88d5","c52cbfff3e90429d882d972b93bfcccd","eb2abbe7443348089a5dfacdb53a5ae4","b9bc198b26ec40ab8dcc4074663cd690","ea2795d79470414ab03bea3e4a0d4bef","8c32d7b14a2246328d09a6bc53108394","e891ddeb227e4849b9e3f10fd375a6ca","1d6059a9dbdf4bc996dad49247be5acf","a068edd28f61459fbfbdd00e79a12ad2","ed7820dea7e842a681fcd54c6de7d9c2","34c13a9bf9d242cb973e96def1c5351b","9623e19644c54167a8280f05c8621148","0d61326de9d04bc3b8acf1c442b7c5a5","5473fc269ea746f88fc4e5134414ac72","64f113dfa090488d93e9be14f875b542","7b548fa98bb24e2988d4bb43598a12b9","7f6a995e8cab40d19ab1424173c33f92","398af8b8e01e4236aa0fd1241510c777","a77ed7c6c4a64f0294efc574bb56d704","9c40b1c7e8684679b32fd37a25701e5c","a65c3a80921348ff9b0018b563315e08","d45322e6753644b3aace55a57a899053","50e57b62a1ab48ff91dcc15d91b6e4c4","d803fbb1bd4d42d4b96cc216f1f097e4","aac3c96bbef14990b23671953644d42d","9d639490509a426e98191ff7b76984bb","fd66982c6bb848fba1dbecd15fd0785d","afd7ad09688e468b966b2c08cb73d595","5e0e9def4c9d496c9f96a63ef821692a","e4dcdc88b8d74e23a4a5009cb642b416","1b902e2b8486442b9464e6951b24a8c9","6ac46039643844d28ba2425721c8a5c9","5e35dde74c5d4924ae53c60c671a6f23","7bbb044b86b64e6fbaca9fc256854cef","09cab07e2aff42e48bc99d88da098cf4","2c290a7b65f64220a6051c4f06f276ac","0c0192fe9db542b5afa56c16c5036f64","4123b0c09eef41529bb174429cae46df","1d5c6ad3806341d08a27d5b0ecf214b7","17d7d7bc81914684b00144040f1bddff","c16d2e66bd574470b2b837d9a5f6d7cb","492130cb24fb477bad7e1fffe6933877","d3e69ae168274f0b8d143b388f85ee83","73384ec56a8c4a8aabf3bd1e29f4a0d9","8c83b2a3317d4fa8a80464a8bd668c7f","41041a45484f4a1ebce88e91df9161e4","b79a8f3c4db740c9bb81f467df9cd0aa","4d66f6f0eb554de1b68aa422e7125ff4","f6f490af1c6540088f86e13d59c23a32","c6819a485c6b42618663bbd1d58516e2","8d90262e5c5b44aead38b2b70c93290b","a4206564cd204a76a54aa4ba61595717","4285a7c0bfab4bf1a8589c9ea66d10ab","33a7893ba7484a4b9bce3f1c89eaa07e","bd70ea5432414690b2d41f4aaa81f87e","8b109529f22b4f51856dc2b8e740cfc6","17017a7262164b5ebaa51594e785e7e9","d0d3465401604a6a8a1cb6917ac620b2","56c96a12c0f3466482c256739bc8a779","777ede93d031476f83c5603053bd3739","21c08e3d21b64824b05545094dae5feb","62cec17a7f824891a5dbb98a9e2ad5ec","dfeb8d170b394fe0a7a1b6877cdecf7e","b1d8e8b63685477cb05389479434376b","c99d585f6f4f4c0eb87837749f6503b4","d1f37f914d0d4df4815a3aacb82e7d05","0effb51c054c4ecbbc2536365d21acd3","2096cf7091c6416dac93b85201ee2948","6714861289b544399c2d6d45d2b85a66","1ada06f0793e4e8bb02900a2125ebc45","db6dceec189e4ae19c05c9da3cd619e7","55fc6f3dd47446c88ec9ad6e82b3e147","bfb37f900edb44f39612d662f2e14388","436b14f19a1b4429839c966f17f82519","f76a7b2af9a1479c89de8e4f9035b9a0","8b29c87757ee46a797f8bb623465bd2c","e91c9c220b084d4dbe12efaa49569b0a","75064be61f9c4894856b472c341ce1c5","8fdc77e40d304edc9ca54b110b22fa70","2b9f3709bef34bc480c7408355d7662d","84c287e808a6489c8547f07c06633ebf","f4c51e8c0bd74a238539c3e31f4dace0","4e99a1c9175a4a91a620561d328c8e63","988b400176584890aff0e7e84d83a15d","3c6ad6c61fa344debfd069d023dc9ec1","76e802486bb9445e8c788b1159427bd4","2ff67574f03d40ebb646150436a4b207","ab0f9946c503444c899746425bc13548","9297d54355cb4b9984139b081958cb94","ad3953880e8d4313be14f3a7e6e066c4","65196dfe55974b17b7fd205fadd32502","d237cc82c7b64cb5a6e4240ac579aef3","012a1fbe10534d7d94c4f958efe15e6f","2e60133f7bba4ed7a30feccae4607143","52f4dca172384408ae1b941487396dc3","c1d5b1c70bd44178994b29ed820ccc74","e0d0379ab2a34e8da5d89f43c7873ce5","92faa36a64af42bf82a50b60876cefd2","38031334fc9e4d44a274be43cc7dbcd5","1fdf789cb1d042de81c08e82c61ad80d","6e43954816c941f18194da79127c9416","10d18aef7f6548a19abe51fbd47485b5","919bdc0e3db546e09fa622620c1012a8","8201bf23e03c4408b6da739b55003b2c","8fdefb82d46542929725028da074b3b5","4145cea1efbe4f2085d003ea35f167fc","e4fb50288bd54b99a66e8f5d76e42ce3","dbbd8efffcdb4f4e870f446a9b186946","6ab9821618c344088585a64a72aaeff1","1c268a8e25964486ae1017398cd35562","3ebcf70f8ee14ddabcd35364a5e37f35","2f99ade6f81f48deac9859c0fe7b9bc4","8b1b43e5fc2c47948d318591b3bb2aae","22b542ee51bd44fb9c0d5db4f6368ad7","94e78eb5ef2e45dea34be0de17bb2ec3","1ca031842e5f47e59ff849c9949e8525","4282b1838605494184874286711b5cff","03ca3a49f62844eb804893d4683132d7","fb0c3021b7e34eb5b4b9e71684cae88b","869b113a56304916b4f77bd9fc4a8ca0","7515dd93242744cebce610e691d4d198","b7a8968f5a5d4ec3b0bde5e14c5a1954","87693d0ff5154bd484bcc9e9cf478c25","d1e23cf46feb43c193b3f27725c0f8a1","a6258a2e17e54f07bfdc57e2e00233db","c820bb426109460b81073f6740958525","21859abbdb704f60abd8e9c9c5073deb","399e02347546452fbc4ffbc168e4c6d4","916d3566bbd54f05b14e36d7dfaf9bc4","45b0506fc4df478d92979aa3ee351f5c","26b23550d0ae43d5a666421855929a41","64286f0c31194488839c2a305474ff3a","a24dff97ba704d16b26061cad8428bf8","84a12223503f494cb2811bd29a920d41","72771edc22524a5d8b4e813bed751cc2","998aabaee70a45faa09f9e1710728ace","7cb8808b906646b2b12432eb762a2b09","932328b6e157405897910ea6977b2459","5bd176ee73954865bfe9df1c311afa60","ce7a1d51ea6249ddb37de53a740911f9","9cce52c5a9ea4f7dad2c948e28d77471","4911f5efa47d440faff3b33aaba91c62","2133bad142a242219e0e0b7603744e70","2d28f9aea1d14c4ea99546d4c644a8bb","3e4f1749003e449ab3ebc7617679373a","30b999c1f7d042ff8d7f35422f8cf3ab","bdbd40078e3447a095989b191db12f3f"]},"id":"HKa_kQVgIQDl","outputId":"462901e8-7bf2-4d9b-d57d-ca212d11ca7e","executionInfo":{"status":"ok","timestamp":1697908495991,"user_tz":-420,"elapsed":70059,"user":{"displayName":"Đức Bùi Duy Anh","userId":"13275453910777475613"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["================= Epoch 1 / 15 =====================\n","Training ... \n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/6 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd6531eea552430bbe5257b0aab09f66"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["step:  0\n","batch:  [tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])]\n","inputids tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(9.0810e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 5.5617, -4.0561],\n","        [ 5.4777, -4.0034],\n","        [ 5.5146, -4.0191],\n","        [ 5.4717, -3.9947],\n","        [-4.8892,  3.9069],\n","        [-4.8396,  3.8826],\n","        [ 5.4903, -4.0080],\n","        [-4.8345,  3.9049],\n","        [ 5.5090, -4.0212],\n","        [ 5.5296, -4.0467],\n","        [ 5.4959, -3.9953],\n","        [ 5.5275, -4.0534],\n","        [ 5.3982, -3.9256],\n","        [ 5.4207, -3.9592],\n","        [ 5.4678, -3.9857],\n","        [ 5.5038, -4.0287]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  1\n","batch:  [tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1])]\n","inputids tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.8453,  3.8883],\n","        [-4.8612,  3.8833],\n","        [ 5.4845, -4.0263],\n","        [ 5.5480, -4.0453],\n","        [-4.8976,  3.9292],\n","        [-4.8448,  3.8838],\n","        [-4.8141,  3.8654],\n","        [ 5.5002, -4.0368],\n","        [ 5.5012, -3.9902],\n","        [ 5.4057, -3.9564],\n","        [ 5.5342, -4.0356],\n","        [ 5.5047, -4.0220],\n","        [-4.7852,  3.8399],\n","        [-4.8765,  3.9221],\n","        [-4.8537,  3.8583],\n","        [-4.9044,  3.9339]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  2\n","batch:  [tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1])]\n","inputids tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.9055,  3.9206],\n","        [ 5.5409, -4.0538],\n","        [-4.7878,  3.8325],\n","        [ 5.5651, -4.0619],\n","        [ 5.5438, -4.0574],\n","        [ 5.4462, -3.9891],\n","        [ 5.5604, -4.0617],\n","        [ 5.4879, -4.0134],\n","        [ 5.5646, -4.0634],\n","        [-4.8969,  3.9036],\n","        [-4.7925,  3.8534],\n","        [ 5.4870, -4.0014],\n","        [ 5.5577, -4.0829],\n","        [-4.8081,  3.8721],\n","        [ 5.5611, -4.0513],\n","        [-4.9281,  3.9506]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  3\n","batch:  [tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0])]\n","inputids tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(8.4195e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 5.5767, -4.0639],\n","        [ 5.4979, -3.9931],\n","        [-4.8538,  3.8772],\n","        [ 5.5611, -4.0533],\n","        [ 5.4605, -3.9824],\n","        [ 5.5056, -4.0342],\n","        [ 5.5584, -4.0811],\n","        [-4.8942,  3.9069],\n","        [ 5.5703, -4.0678],\n","        [ 5.4870, -4.0328],\n","        [ 5.5611, -4.0765],\n","        [ 5.5684, -4.0750],\n","        [-4.9289,  3.9580],\n","        [ 5.5102, -4.0278],\n","        [ 5.6027, -4.0735],\n","        [ 5.5283, -4.0412]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  4\n","batch:  [tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0])]\n","inputids tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.9199,  3.9506],\n","        [-4.8661,  3.8902],\n","        [ 5.5704, -4.0704],\n","        [ 5.6113, -4.1120],\n","        [-4.8695,  3.9301],\n","        [ 5.5778, -4.0654],\n","        [ 5.4975, -4.0187],\n","        [-4.9066,  3.9429],\n","        [ 5.5282, -4.0382],\n","        [ 5.5335, -4.0599],\n","        [ 5.6313, -4.1104],\n","        [ 5.6043, -4.1073],\n","        [-4.8659,  3.9048],\n","        [-4.8358,  3.8885],\n","        [-4.9342,  3.9897],\n","        [ 5.5841, -4.0836]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  5\n","batch:  [tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1])]\n","inputids tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([10, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([10, 256])\n","labels:  tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n","labels:  torch.Size([10])\n","outputs:  SequenceClassifierOutput(loss=tensor(8.9533e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 5.4651, -4.0060],\n","        [-4.9397,  3.9561],\n","        [ 5.5260, -4.0498],\n","        [ 5.6074, -4.0786],\n","        [ 5.5423, -4.0621],\n","        [-4.9308,  3.9595],\n","        [ 5.5818, -4.0919],\n","        [ 5.5396, -4.0588],\n","        [ 5.6104, -4.1203],\n","        [-4.8655,  3.9097]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([10, 2])\n","Accuracy: 1.0000\n"," F1 score: 1.0000\n"," Average training loss: 0.0001\n","Running Validation...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa615f53008a42d188734530fa2b7c23"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":[" Accuracy: 0.8000\n"," F1 score: 0.7619\n","Saved model to /content/drive/MyDrive\n","================= Epoch 2 / 15 =====================\n","Training ... \n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/6 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe97f5ea3dc3428d9724b448dd0a8cb4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["step:  0\n","batch:  [tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])]\n","inputids tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(7.7982e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 5.5486, -4.0658],\n","        [ 5.4629, -3.9961],\n","        [ 5.6136, -4.1083],\n","        [ 5.6192, -4.1287],\n","        [-4.9409,  3.9635],\n","        [-4.8642,  3.9055],\n","        [ 5.6193, -4.1149],\n","        [-4.9504,  3.9753],\n","        [ 5.5465, -4.0570],\n","        [ 5.6086, -4.1297],\n","        [ 5.5500, -4.0810],\n","        [ 5.6086, -4.0871],\n","        [ 5.6234, -4.1075],\n","        [ 5.6201, -4.1046],\n","        [ 5.5888, -4.0895],\n","        [ 5.5462, -4.0803]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  1\n","batch:  [tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1])]\n","inputids tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.9343,  3.9517],\n","        [-4.8961,  3.9125],\n","        [ 5.5739, -4.0899],\n","        [ 5.5746, -4.0967],\n","        [-5.0003,  4.0094],\n","        [-5.0193,  4.0296],\n","        [-4.9002,  3.9268],\n","        [ 5.6863, -4.1798],\n","        [ 5.5010, -4.0345],\n","        [ 5.5896, -4.1000],\n","        [ 5.5975, -4.1019],\n","        [ 5.5961, -4.1341],\n","        [-4.9610,  3.9877],\n","        [-4.9771,  3.9861],\n","        [-4.9288,  3.9759],\n","        [-5.0174,  4.0117]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  2\n","batch:  [tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1])]\n","inputids tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(8.2124e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.0181,  4.0136],\n","        [ 5.6823, -4.1727],\n","        [-5.0350,  4.0307],\n","        [ 5.7060, -4.1835],\n","        [ 5.6814, -4.1520],\n","        [ 5.7025, -4.1640],\n","        [ 5.6785, -4.1579],\n","        [ 5.6626, -4.1518],\n","        [ 5.6342, -4.1202],\n","        [-4.9720,  3.9783],\n","        [-4.9282,  3.9574],\n","        [ 5.6838, -4.1649],\n","        [ 5.6531, -4.1262],\n","        [-4.9026,  3.9276],\n","        [ 5.6880, -4.1664],\n","        [-4.9696,  3.9969]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  3\n","batch:  [tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0])]\n","inputids tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(6.5600e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 5.7091, -4.1754],\n","        [ 5.6967, -4.1793],\n","        [-5.0359,  4.0331],\n","        [ 5.7374, -4.2008],\n","        [ 5.6026, -4.1157],\n","        [ 5.6121, -4.1264],\n","        [ 5.6339, -4.1393],\n","        [-4.9999,  4.0221],\n","        [ 5.6738, -4.1563],\n","        [ 5.6834, -4.1785],\n","        [ 5.7328, -4.2112],\n","        [ 5.6369, -4.1574],\n","        [-5.0115,  4.0401],\n","        [ 5.6385, -4.1284],\n","        [ 5.6871, -4.1754],\n","        [ 5.7101, -4.1802]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  4\n","batch:  [tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0])]\n","inputids tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(7.8473e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.0042,  4.0214],\n","        [-5.0295,  4.0131],\n","        [ 5.7342, -4.2146],\n","        [ 5.7438, -4.2061],\n","        [-5.0910,  4.0721],\n","        [ 5.6882, -4.1710],\n","        [ 5.7067, -4.1868],\n","        [-4.9967,  4.0178],\n","        [ 5.6868, -4.1541],\n","        [ 5.6195, -4.1267],\n","        [ 5.7081, -4.1764],\n","        [ 5.7314, -4.2050],\n","        [-5.0993,  4.0766],\n","        [-5.0703,  4.0716],\n","        [-5.0231,  4.0520],\n","        [ 5.6395, -4.1445]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  5\n","batch:  [tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1])]\n","inputids tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([10, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([10, 256])\n","labels:  tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n","labels:  torch.Size([10])\n","outputs:  SequenceClassifierOutput(loss=tensor(6.7446e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 5.6670, -4.1775],\n","        [-5.0906,  4.1007],\n","        [ 5.6871, -4.1916],\n","        [ 5.7752, -4.2689],\n","        [ 5.6910, -4.1631],\n","        [-5.0540,  4.0590],\n","        [ 5.6565, -4.1586],\n","        [ 5.6185, -4.1291],\n","        [ 5.7565, -4.2571],\n","        [-5.0832,  4.0856]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([10, 2])\n","Accuracy: 1.0000\n"," F1 score: 1.0000\n"," Average training loss: 0.0001\n","Running Validation...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d11d8eb79e5e4bd78e1b68bdbdb61ad5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":[" Accuracy: 0.8000\n"," F1 score: 0.7619\n","================= Epoch 3 / 15 =====================\n","Training ... \n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/6 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa0e20b020ff4db4aea99e927b8d107f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["step:  0\n","batch:  [tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])]\n","inputids tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(5.7412e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 5.7839, -4.2558],\n","        [ 5.7395, -4.2396],\n","        [ 5.8220, -4.2763],\n","        [ 5.7289, -4.2047],\n","        [-5.1282,  4.0854],\n","        [-5.0249,  4.0409],\n","        [ 5.8006, -4.2808],\n","        [-5.1190,  4.1254],\n","        [ 5.6577, -4.1765],\n","        [ 5.7084, -4.2042],\n","        [ 5.7627, -4.2432],\n","        [ 5.8023, -4.2782],\n","        [ 5.6911, -4.1891],\n","        [ 5.7803, -4.2396],\n","        [ 5.7514, -4.2163],\n","        [ 5.6803, -4.1729]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  1\n","batch:  [tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1])]\n","inputids tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(7.6812e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.1010,  4.0972],\n","        [-5.1308,  4.1299],\n","        [ 5.7415, -4.2264],\n","        [ 5.7651, -4.2135],\n","        [-5.0887,  4.1030],\n","        [-5.1112,  4.1076],\n","        [-5.1083,  4.0904],\n","        [ 5.8419, -4.2953],\n","        [ 5.7601, -4.2365],\n","        [ 5.8070, -4.2939],\n","        [ 5.8140, -4.2880],\n","        [ 5.8284, -4.2915],\n","        [-5.0162,  4.0354],\n","        [-5.1353,  4.1417],\n","        [-4.9956,  3.9980],\n","        [-5.1340,  4.1305]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  2\n","batch:  [tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1])]\n","inputids tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(6.2881e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.1270,  4.1424],\n","        [ 5.8393, -4.2950],\n","        [-5.1203,  4.1193],\n","        [ 5.8327, -4.3266],\n","        [ 5.7693, -4.2489],\n","        [ 5.7871, -4.2774],\n","        [ 5.8819, -4.3502],\n","        [ 5.7932, -4.2808],\n","        [ 5.7789, -4.2799],\n","        [-5.0713,  4.0822],\n","        [-5.1141,  4.1079],\n","        [ 5.8211, -4.2770],\n","        [ 5.7304, -4.2215],\n","        [-5.1155,  4.1188],\n","        [ 5.7907, -4.2658],\n","        [-5.1372,  4.1342]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  3\n","batch:  [tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0])]\n","inputids tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(4.9888e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 5.8218, -4.2801],\n","        [ 5.7998, -4.2641],\n","        [-5.1548,  4.1528],\n","        [ 5.8217, -4.3123],\n","        [ 5.7623, -4.2534],\n","        [ 5.8616, -4.3243],\n","        [ 5.7942, -4.2571],\n","        [-5.1519,  4.1529],\n","        [ 5.8394, -4.2872],\n","        [ 5.8806, -4.3220],\n","        [ 5.8802, -4.3203],\n","        [ 5.8055, -4.2816],\n","        [-5.1633,  4.1608],\n","        [ 5.7948, -4.2747],\n","        [ 5.8768, -4.3155],\n","        [ 5.7943, -4.2637]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  4\n","batch:  [tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0])]\n","inputids tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(5.9044e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.1984,  4.1747],\n","        [-5.1861,  4.1762],\n","        [ 5.8400, -4.3120],\n","        [ 5.8458, -4.2999],\n","        [-5.2486,  4.2155],\n","        [ 5.8508, -4.3173],\n","        [ 5.8404, -4.3401],\n","        [-5.2143,  4.1935],\n","        [ 5.8999, -4.3582],\n","        [ 5.7988, -4.2601],\n","        [ 5.8060, -4.2724],\n","        [ 5.7171, -4.2166],\n","        [-5.1651,  4.1611],\n","        [-5.2686,  4.2142],\n","        [-5.1968,  4.1968],\n","        [ 5.7781, -4.2797]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  5\n","batch:  [tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1])]\n","inputids tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([10, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([10, 256])\n","labels:  tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n","labels:  torch.Size([10])\n","outputs:  SequenceClassifierOutput(loss=tensor(5.3631e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 5.8788, -4.3433],\n","        [-5.1971,  4.1857],\n","        [ 5.8584, -4.3182],\n","        [ 5.8491, -4.3242],\n","        [ 5.8421, -4.3245],\n","        [-5.1927,  4.1695],\n","        [ 5.8048, -4.2836],\n","        [ 5.8429, -4.3302],\n","        [ 5.8753, -4.3259],\n","        [-5.1148,  4.1106]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([10, 2])\n","Accuracy: 1.0000\n"," F1 score: 1.0000\n"," Average training loss: 0.0001\n","Running Validation...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0323a38c89144b408ef401b736f26837"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":[" Accuracy: 0.8000\n"," F1 score: 0.7619\n","================= Epoch 4 / 15 =====================\n","Training ... \n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/6 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"014217f6e5b24a338054c3ffb990f31f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["step:  0\n","batch:  [tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])]\n","inputids tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(4.2043e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 5.9573, -4.4010],\n","        [ 5.9053, -4.3767],\n","        [ 5.9021, -4.3610],\n","        [ 5.9215, -4.3547],\n","        [-5.2758,  4.2438],\n","        [-5.2383,  4.2409],\n","        [ 5.9197, -4.3873],\n","        [-5.3302,  4.2864],\n","        [ 5.9546, -4.3981],\n","        [ 5.8662, -4.3205],\n","        [ 5.9342, -4.3903],\n","        [ 5.8717, -4.3310],\n","        [ 5.9304, -4.3707],\n","        [ 5.9024, -4.3951],\n","        [ 5.8573, -4.3222],\n","        [ 5.7919, -4.2679]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  1\n","batch:  [tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1])]\n","inputids tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(5.9915e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.2255,  4.2176],\n","        [-5.2197,  4.1911],\n","        [ 5.9364, -4.3976],\n","        [ 5.9685, -4.4168],\n","        [-5.2315,  4.1943],\n","        [-5.2743,  4.2461],\n","        [-5.2337,  4.2250],\n","        [ 5.9429, -4.3809],\n","        [ 5.9028, -4.3738],\n","        [ 5.9405, -4.4023],\n","        [ 5.9091, -4.3483],\n","        [ 5.8730, -4.3597],\n","        [-5.1525,  4.1434],\n","        [-5.2452,  4.2407],\n","        [-5.2539,  4.2342],\n","        [-5.1652,  4.1710]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  2\n","batch:  [tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1])]\n","inputids tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(4.8025e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.3322,  4.2801],\n","        [ 5.9516, -4.4040],\n","        [-5.2672,  4.2514],\n","        [ 5.8583, -4.3204],\n","        [ 5.9494, -4.4147],\n","        [ 5.9333, -4.4171],\n","        [ 6.0137, -4.4370],\n","        [ 5.9768, -4.4185],\n","        [ 6.0159, -4.4431],\n","        [-5.1712,  4.1900],\n","        [-5.2930,  4.2603],\n","        [ 5.9161, -4.3802],\n","        [ 5.9170, -4.3827],\n","        [-5.2333,  4.2062],\n","        [ 6.0053, -4.4234],\n","        [-5.2795,  4.2432]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  3\n","batch:  [tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0])]\n","inputids tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(3.7543e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 5.9883, -4.4588],\n","        [ 6.0627, -4.4878],\n","        [-5.3284,  4.2736],\n","        [ 5.9936, -4.4496],\n","        [ 6.0013, -4.4332],\n","        [ 5.9503, -4.4268],\n","        [ 5.9720, -4.4096],\n","        [-5.3238,  4.3081],\n","        [ 6.0207, -4.4486],\n","        [ 5.9708, -4.4232],\n","        [ 5.9821, -4.4289],\n","        [ 6.0170, -4.4706],\n","        [-5.2182,  4.2188],\n","        [ 5.9472, -4.3955],\n","        [ 5.9191, -4.3918],\n","        [ 6.0060, -4.4295]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  4\n","batch:  [tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0])]\n","inputids tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(4.6513e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.3269,  4.2909],\n","        [-5.3268,  4.2838],\n","        [ 6.0496, -4.4800],\n","        [ 5.9210, -4.4042],\n","        [-5.3017,  4.2839],\n","        [ 6.0462, -4.4710],\n","        [ 6.0240, -4.4585],\n","        [-5.3095,  4.2552],\n","        [ 5.9930, -4.4523],\n","        [ 5.8644, -4.3105],\n","        [ 5.9978, -4.4457],\n","        [ 6.0199, -4.4720],\n","        [-5.3721,  4.3096],\n","        [-5.2917,  4.2907],\n","        [-5.3030,  4.2640],\n","        [ 5.9483, -4.4062]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  5\n","batch:  [tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1])]\n","inputids tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([10, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([10, 256])\n","labels:  tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n","labels:  torch.Size([10])\n","outputs:  SequenceClassifierOutput(loss=tensor(4.1996e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 5.8605, -4.3730],\n","        [-5.3341,  4.2897],\n","        [ 6.0062, -4.4887],\n","        [ 6.0416, -4.4866],\n","        [ 5.8708, -4.3727],\n","        [-5.3186,  4.2869],\n","        [ 6.0001, -4.4215],\n","        [ 5.9780, -4.4287],\n","        [ 5.9683, -4.4131],\n","        [-5.2874,  4.2895]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([10, 2])\n","Accuracy: 1.0000\n"," F1 score: 1.0000\n"," Average training loss: 0.0000\n","Running Validation...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f342c14a6f804e6f932f6a942bc2727e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":[" Accuracy: 0.8000\n"," F1 score: 0.7619\n","================= Epoch 5 / 15 =====================\n","Training ... \n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/6 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4fcd7bea02d4d93ae344215eb243e58"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["step:  0\n","batch:  [tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])]\n","inputids tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(3.4145e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.0466, -4.4935],\n","        [ 6.0435, -4.5040],\n","        [ 6.0582, -4.4933],\n","        [ 6.0306, -4.4723],\n","        [-5.3079,  4.2509],\n","        [-5.3242,  4.2958],\n","        [ 5.9732, -4.4218],\n","        [-5.4136,  4.3777],\n","        [ 6.0272, -4.4491],\n","        [ 5.9804, -4.4005],\n","        [ 6.0806, -4.5011],\n","        [ 6.1022, -4.5120],\n","        [ 5.9997, -4.4497],\n","        [ 6.0509, -4.4749],\n","        [ 6.1300, -4.5320],\n","        [ 6.0160, -4.4592]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  1\n","batch:  [tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1])]\n","inputids tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(4.4822e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.4039,  4.3706],\n","        [-5.3767,  4.3423],\n","        [ 6.0072, -4.4601],\n","        [ 6.1005, -4.5067],\n","        [-5.4492,  4.3872],\n","        [-5.3041,  4.2912],\n","        [-5.4700,  4.3985],\n","        [ 6.0679, -4.4997],\n","        [ 6.0228, -4.4674],\n","        [ 6.0481, -4.4991],\n","        [ 6.1075, -4.5370],\n","        [ 6.0893, -4.5124],\n","        [-5.2348,  4.2217],\n","        [-5.4158,  4.3615],\n","        [-5.4267,  4.3771],\n","        [-5.4375,  4.3723]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  2\n","batch:  [tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1])]\n","inputids tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(3.6693e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.4090,  4.3657],\n","        [ 6.1137, -4.5495],\n","        [-5.3861,  4.3503],\n","        [ 6.1335, -4.5303],\n","        [ 6.1872, -4.5923],\n","        [ 6.1002, -4.5295],\n","        [ 6.1422, -4.5535],\n","        [ 6.1252, -4.5290],\n","        [ 6.1151, -4.5180],\n","        [-5.4491,  4.4024],\n","        [-5.3330,  4.3147],\n","        [ 6.1260, -4.5299],\n","        [ 6.1188, -4.5703],\n","        [-5.3550,  4.3167],\n","        [ 5.9906, -4.4290],\n","        [-5.4585,  4.3978]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  3\n","batch:  [tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0])]\n","inputids tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(2.9303e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.1403, -4.5669],\n","        [ 6.0656, -4.5076],\n","        [-5.4908,  4.4319],\n","        [ 6.1806, -4.5870],\n","        [ 6.1682, -4.5763],\n","        [ 6.0416, -4.4806],\n","        [ 6.0364, -4.4863],\n","        [-5.4012,  4.3848],\n","        [ 6.1576, -4.5719],\n","        [ 6.1452, -4.5575],\n","        [ 6.1501, -4.5678],\n","        [ 6.1347, -4.5648],\n","        [-5.4002,  4.3531],\n","        [ 6.1101, -4.5465],\n","        [ 6.0888, -4.4945],\n","        [ 6.1285, -4.5620]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  4\n","batch:  [tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0])]\n","inputids tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(3.7349e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.4011,  4.3635],\n","        [-5.3966,  4.3663],\n","        [ 6.0891, -4.5308],\n","        [ 6.1765, -4.5812],\n","        [-5.4326,  4.3856],\n","        [ 5.9470, -4.4481],\n","        [ 6.1167, -4.5438],\n","        [-5.5060,  4.4488],\n","        [ 6.1669, -4.5590],\n","        [ 6.0995, -4.5115],\n","        [ 6.1078, -4.5471],\n","        [ 6.0456, -4.5101],\n","        [-5.5031,  4.4385],\n","        [-5.3728,  4.3520],\n","        [-5.4426,  4.3937],\n","        [ 6.1312, -4.5508]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  5\n","batch:  [tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1])]\n","inputids tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([10, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([10, 256])\n","labels:  tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n","labels:  torch.Size([10])\n","outputs:  SequenceClassifierOutput(loss=tensor(3.3068e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.0771, -4.5164],\n","        [-5.3659,  4.3524],\n","        [ 6.0279, -4.4917],\n","        [ 6.1580, -4.5853],\n","        [ 6.1048, -4.5176],\n","        [-5.4931,  4.4326],\n","        [ 6.1158, -4.5487],\n","        [ 6.1711, -4.5940],\n","        [ 6.1485, -4.5702],\n","        [-5.4212,  4.3506]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([10, 2])\n","Accuracy: 1.0000\n"," F1 score: 1.0000\n"," Average training loss: 0.0000\n","Running Validation...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ef0d057a69c455bb7e097fa12733d73"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":[" Accuracy: 0.8000\n"," F1 score: 0.7619\n","================= Epoch 6 / 15 =====================\n","Training ... \n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/6 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6fedbbb1c254d26a7949a0b8ffbf61f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["step:  0\n","batch:  [tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])]\n","inputids tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(2.7552e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.2185, -4.6335],\n","        [ 6.1483, -4.5671],\n","        [ 6.0927, -4.5404],\n","        [ 6.1606, -4.5749],\n","        [-5.4983,  4.4313],\n","        [-5.4452,  4.4033],\n","        [ 6.0769, -4.5155],\n","        [-5.4792,  4.4271],\n","        [ 6.0945, -4.5173],\n","        [ 6.1476, -4.6008],\n","        [ 6.1367, -4.5569],\n","        [ 6.1457, -4.5760],\n","        [ 6.0907, -4.5284],\n","        [ 6.2613, -4.6684],\n","        [ 6.1677, -4.5791],\n","        [ 6.1393, -4.5706]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  1\n","batch:  [tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1])]\n","inputids tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(3.6291e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.5883,  4.5039],\n","        [-5.5201,  4.4444],\n","        [ 6.2162, -4.6357],\n","        [ 6.1841, -4.5956],\n","        [-5.4536,  4.3983],\n","        [-5.4843,  4.4130],\n","        [-5.5362,  4.4731],\n","        [ 6.2189, -4.6294],\n","        [ 6.1810, -4.5942],\n","        [ 6.1701, -4.5913],\n","        [ 6.1569, -4.6147],\n","        [ 6.1997, -4.6159],\n","        [-5.4159,  4.4127],\n","        [-5.4888,  4.4281],\n","        [-5.4383,  4.4136],\n","        [-5.5228,  4.4704]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  2\n","batch:  [tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1])]\n","inputids tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(3.1158e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.4647,  4.3913],\n","        [ 6.2042, -4.6094],\n","        [-5.4461,  4.4353],\n","        [ 6.0127, -4.4691],\n","        [ 6.1422, -4.5980],\n","        [ 6.2425, -4.6465],\n","        [ 6.2154, -4.6234],\n","        [ 6.1941, -4.6215],\n","        [ 6.2365, -4.6147],\n","        [-5.5998,  4.4971],\n","        [-5.4773,  4.4331],\n","        [ 6.1029, -4.5409],\n","        [ 6.1821, -4.6018],\n","        [-5.5338,  4.4688],\n","        [ 6.2259, -4.6321],\n","        [-5.5153,  4.4457]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  3\n","batch:  [tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0])]\n","inputids tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(2.3886e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.2310, -4.6431],\n","        [ 6.2995, -4.6995],\n","        [-5.5939,  4.5129],\n","        [ 6.1991, -4.6247],\n","        [ 6.2305, -4.6005],\n","        [ 6.2228, -4.6226],\n","        [ 6.1909, -4.6223],\n","        [-5.5780,  4.4996],\n","        [ 6.2177, -4.6565],\n","        [ 6.2158, -4.6372],\n","        [ 6.1736, -4.5953],\n","        [ 6.1854, -4.6118],\n","        [-5.4731,  4.4358],\n","        [ 6.2072, -4.6302],\n","        [ 6.2985, -4.6879],\n","        [ 6.2642, -4.6464]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  4\n","batch:  [tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0])]\n","inputids tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(2.9973e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.5589,  4.4926],\n","        [-5.5611,  4.5001],\n","        [ 6.2241, -4.6263],\n","        [ 6.2334, -4.6546],\n","        [-5.5224,  4.4662],\n","        [ 6.1815, -4.6024],\n","        [ 6.1179, -4.5654],\n","        [-5.5628,  4.4752],\n","        [ 6.1958, -4.6320],\n","        [ 6.1450, -4.5531],\n","        [ 6.2598, -4.6646],\n","        [ 6.2093, -4.6161],\n","        [-5.5576,  4.4971],\n","        [-5.5916,  4.5073],\n","        [-5.5956,  4.5318],\n","        [ 6.2546, -4.6674]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  5\n","batch:  [tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1])]\n","inputids tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([10, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([10, 256])\n","labels:  tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n","labels:  torch.Size([10])\n","outputs:  SequenceClassifierOutput(loss=tensor(2.7263e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.1550, -4.5681],\n","        [-5.5448,  4.4751],\n","        [ 6.2313, -4.6480],\n","        [ 6.2847, -4.6815],\n","        [ 6.1697, -4.5935],\n","        [-5.5228,  4.4610],\n","        [ 6.2678, -4.6730],\n","        [ 6.1658, -4.5985],\n","        [ 6.3385, -4.7211],\n","        [-5.5118,  4.4320]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([10, 2])\n","Accuracy: 1.0000\n"," F1 score: 1.0000\n"," Average training loss: 0.0000\n","Running Validation...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89827b2bbb6f439f8884f1db8fb7f92e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":[" Accuracy: 0.8000\n"," F1 score: 0.7619\n","================= Epoch 7 / 15 =====================\n","Training ... \n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/6 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebde6c17a099484eb818784fe058e68d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["step:  0\n","batch:  [tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])]\n","inputids tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(2.1614e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.2679, -4.6632],\n","        [ 6.3139, -4.7037],\n","        [ 6.2950, -4.6775],\n","        [ 6.3167, -4.7173],\n","        [-5.6661,  4.5822],\n","        [-5.6107,  4.5232],\n","        [ 6.2327, -4.6596],\n","        [-5.6311,  4.5485],\n","        [ 6.1826, -4.6106],\n","        [ 6.2191, -4.6283],\n","        [ 6.2448, -4.6634],\n","        [ 6.2786, -4.6770],\n","        [ 6.2682, -4.6826],\n","        [ 6.2600, -4.6730],\n","        [ 6.2952, -4.7015],\n","        [ 6.2448, -4.6440]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  1\n","batch:  [tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1])]\n","inputids tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(3.0666e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.5656,  4.4968],\n","        [-5.6880,  4.5905],\n","        [ 6.3344, -4.6962],\n","        [ 6.3004, -4.6930],\n","        [-5.5914,  4.5263],\n","        [-5.5916,  4.5104],\n","        [-5.5595,  4.4738],\n","        [ 6.3072, -4.6851],\n","        [ 6.2638, -4.6870],\n","        [ 6.2459, -4.6376],\n","        [ 6.2253, -4.6293],\n","        [ 6.3144, -4.7075],\n","        [-5.5831,  4.5185],\n","        [-5.6646,  4.5466],\n","        [-5.5068,  4.4135],\n","        [-5.6123,  4.5197]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  2\n","batch:  [tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1])]\n","inputids tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(2.5197e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.5699,  4.5022],\n","        [ 6.3229, -4.7055],\n","        [-5.6067,  4.5520],\n","        [ 6.3178, -4.7164],\n","        [ 6.3306, -4.7120],\n","        [ 6.2640, -4.6711],\n","        [ 6.2828, -4.6962],\n","        [ 6.2452, -4.6529],\n","        [ 6.3500, -4.7149],\n","        [-5.6806,  4.5983],\n","        [-5.6432,  4.5648],\n","        [ 6.2589, -4.6805],\n","        [ 6.2386, -4.6608],\n","        [-5.5982,  4.5207],\n","        [ 6.2597, -4.6550],\n","        [-5.6087,  4.5444]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  3\n","batch:  [tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0])]\n","inputids tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(2.0772e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.3303, -4.7239],\n","        [ 6.2549, -4.6584],\n","        [-5.6601,  4.5557],\n","        [ 6.2375, -4.6478],\n","        [ 6.3657, -4.7357],\n","        [ 6.2116, -4.6369],\n","        [ 6.3126, -4.7236],\n","        [-5.7213,  4.6432],\n","        [ 6.3264, -4.7158],\n","        [ 6.3101, -4.7269],\n","        [ 6.1468, -4.5951],\n","        [ 6.2876, -4.7121],\n","        [-5.6265,  4.5268],\n","        [ 6.2783, -4.6878],\n","        [ 6.3337, -4.7261],\n","        [ 6.2447, -4.6601]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  4\n","batch:  [tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0])]\n","inputids tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(2.5078e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.6145,  4.5264],\n","        [-5.6254,  4.5624],\n","        [ 6.3461, -4.7330],\n","        [ 6.3518, -4.7424],\n","        [-5.6888,  4.6024],\n","        [ 6.2927, -4.6852],\n","        [ 6.3500, -4.7390],\n","        [-5.6505,  4.5604],\n","        [ 6.2539, -4.6887],\n","        [ 6.2566, -4.6625],\n","        [ 6.3605, -4.7458],\n","        [ 6.3423, -4.7267],\n","        [-5.7121,  4.6119],\n","        [-5.6566,  4.5583],\n","        [-5.6036,  4.5293],\n","        [ 6.3594, -4.7446]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  5\n","batch:  [tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1])]\n","inputids tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([10, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([10, 256])\n","labels:  tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n","labels:  torch.Size([10])\n","outputs:  SequenceClassifierOutput(loss=tensor(2.1529e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.3319, -4.7246],\n","        [-5.6979,  4.5967],\n","        [ 6.2692, -4.6942],\n","        [ 6.3373, -4.7261],\n","        [ 6.3039, -4.7074],\n","        [-5.6583,  4.5759],\n","        [ 6.3032, -4.7229],\n","        [ 6.4202, -4.8026],\n","        [ 6.3581, -4.7442],\n","        [-5.6596,  4.5776]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([10, 2])\n","Accuracy: 1.0000\n"," F1 score: 1.0000\n"," Average training loss: 0.0000\n","Running Validation...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9dc9efa2fa04bd6a18c81ea56a25471"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":[" Accuracy: 0.8000\n"," F1 score: 0.7619\n","================= Epoch 8 / 15 =====================\n","Training ... \n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/6 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f886ec0dbaa0410ab78be1f545b2bd9a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["step:  0\n","batch:  [tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])]\n","inputids tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.9930e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.3545, -4.7588],\n","        [ 6.3248, -4.7368],\n","        [ 6.3611, -4.7451],\n","        [ 6.2302, -4.6750],\n","        [-5.6511,  4.5701],\n","        [-5.6464,  4.5545],\n","        [ 6.3770, -4.7677],\n","        [-5.6623,  4.5766],\n","        [ 6.3389, -4.7371],\n","        [ 6.3213, -4.7367],\n","        [ 6.2704, -4.6682],\n","        [ 6.2040, -4.6505],\n","        [ 6.2497, -4.6882],\n","        [ 6.3811, -4.7656],\n","        [ 6.3980, -4.7732],\n","        [ 6.2950, -4.7112]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  1\n","batch:  [tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1])]\n","inputids tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(2.5622e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.7466,  4.6630],\n","        [-5.6875,  4.6055],\n","        [ 6.2991, -4.7164],\n","        [ 6.4102, -4.7805],\n","        [-5.7549,  4.6601],\n","        [-5.6757,  4.5958],\n","        [-5.6743,  4.5748],\n","        [ 6.3636, -4.7571],\n","        [ 6.3276, -4.7290],\n","        [ 6.3919, -4.7680],\n","        [ 6.3165, -4.7246],\n","        [ 6.3903, -4.7746],\n","        [-5.6391,  4.5748],\n","        [-5.7556,  4.6272],\n","        [-5.6286,  4.5310],\n","        [-5.6776,  4.5939]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  2\n","batch:  [tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1])]\n","inputids tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(2.1971e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.6979,  4.6089],\n","        [ 6.4137, -4.8068],\n","        [-5.6216,  4.5657],\n","        [ 6.3760, -4.7446],\n","        [ 6.3743, -4.7461],\n","        [ 6.3293, -4.7513],\n","        [ 6.4078, -4.7947],\n","        [ 6.3515, -4.7622],\n","        [ 6.4019, -4.7899],\n","        [-5.7986,  4.6877],\n","        [-5.6349,  4.5777],\n","        [ 6.3603, -4.7680],\n","        [ 6.3155, -4.7154],\n","        [-5.6566,  4.5489],\n","        [ 6.3996, -4.7862],\n","        [-5.6975,  4.6034]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  3\n","batch:  [tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0])]\n","inputids tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.8060e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.4891, -4.8379],\n","        [ 6.2328, -4.6356],\n","        [-5.7264,  4.6010],\n","        [ 6.3345, -4.7408],\n","        [ 6.3661, -4.7584],\n","        [ 6.4297, -4.8291],\n","        [ 6.3961, -4.7994],\n","        [-5.7223,  4.6280],\n","        [ 6.4190, -4.8182],\n","        [ 6.3850, -4.7859],\n","        [ 6.4245, -4.7928],\n","        [ 6.5033, -4.8627],\n","        [-5.6446,  4.5862],\n","        [ 6.2101, -4.6462],\n","        [ 6.3820, -4.7621],\n","        [ 6.3827, -4.7816]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  4\n","batch:  [tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0])]\n","inputids tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(2.1971e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.7064,  4.6250],\n","        [-5.6929,  4.6030],\n","        [ 6.3995, -4.8014],\n","        [ 6.3301, -4.7431],\n","        [-5.7966,  4.6757],\n","        [ 6.3258, -4.7221],\n","        [ 6.3971, -4.7821],\n","        [-5.8097,  4.6862],\n","        [ 6.4420, -4.8026],\n","        [ 6.3071, -4.7136],\n","        [ 6.3991, -4.7741],\n","        [ 6.3974, -4.8068],\n","        [-5.7651,  4.6546],\n","        [-5.6328,  4.5720],\n","        [-5.7218,  4.6178],\n","        [ 6.3898, -4.7812]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  5\n","batch:  [tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1])]\n","inputids tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([10, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([10, 256])\n","labels:  tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n","labels:  torch.Size([10])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.9192e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.3752, -4.7613],\n","        [-5.7851,  4.6865],\n","        [ 6.2804, -4.7024],\n","        [ 6.3784, -4.7747],\n","        [ 6.3992, -4.7932],\n","        [-5.7394,  4.6613],\n","        [ 6.3846, -4.7886],\n","        [ 6.4234, -4.7809],\n","        [ 6.4408, -4.8269],\n","        [-5.7061,  4.6119]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([10, 2])\n","Accuracy: 1.0000\n"," F1 score: 1.0000\n"," Average training loss: 0.0000\n","Running Validation...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03c310a76f2e4cd29faceb3e5212466e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":[" Accuracy: 0.8000\n"," F1 score: 0.7619\n","================= Epoch 9 / 15 =====================\n","Training ... \n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/6 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5f19f16c2f4411a9a69b898598cee3f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["step:  0\n","batch:  [tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])]\n","inputids tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.7308e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.4604, -4.8096],\n","        [ 6.3698, -4.7707],\n","        [ 6.3643, -4.7710],\n","        [ 6.3789, -4.7619],\n","        [-5.8036,  4.6982],\n","        [-5.7334,  4.6337],\n","        [ 6.3902, -4.7771],\n","        [-5.7645,  4.6774],\n","        [ 6.3985, -4.7941],\n","        [ 6.4366, -4.8532],\n","        [ 6.2959, -4.7115],\n","        [ 6.3931, -4.7740],\n","        [ 6.2924, -4.7107],\n","        [ 6.3787, -4.7622],\n","        [ 6.3910, -4.7720],\n","        [ 6.3063, -4.7583]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  1\n","batch:  [tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1])]\n","inputids tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(2.2858e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.7513,  4.6491],\n","        [-5.7708,  4.6843],\n","        [ 6.4373, -4.8304],\n","        [ 6.3794, -4.7519],\n","        [-5.8159,  4.7003],\n","        [-5.7240,  4.6385],\n","        [-5.7013,  4.5850],\n","        [ 6.4632, -4.8404],\n","        [ 6.4295, -4.8329],\n","        [ 6.4743, -4.8524],\n","        [ 6.4373, -4.8120],\n","        [ 6.4374, -4.8251],\n","        [-5.6864,  4.5972],\n","        [-5.8063,  4.7091],\n","        [-5.7442,  4.6546],\n","        [-5.7247,  4.6419]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  2\n","batch:  [tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1])]\n","inputids tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.9647e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.7578,  4.6799],\n","        [ 6.4375, -4.8105],\n","        [-5.8298,  4.6983],\n","        [ 6.2950, -4.7193],\n","        [ 6.4765, -4.8734],\n","        [ 6.4123, -4.7976],\n","        [ 6.4980, -4.8552],\n","        [ 6.4472, -4.8313],\n","        [ 6.3845, -4.7867],\n","        [-5.7316,  4.6428],\n","        [-5.6896,  4.6314],\n","        [ 6.4218, -4.7925],\n","        [ 6.3910, -4.7739],\n","        [-5.7178,  4.6277],\n","        [ 6.4441, -4.8142],\n","        [-5.7919,  4.6859]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  3\n","batch:  [tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0])]\n","inputids tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.5899e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.4977, -4.8789],\n","        [ 6.4108, -4.8238],\n","        [-5.7945,  4.7157],\n","        [ 6.4823, -4.8556],\n","        [ 6.4354, -4.8034],\n","        [ 6.4497, -4.8126],\n","        [ 6.3787, -4.8014],\n","        [-5.7630,  4.6547],\n","        [ 6.4353, -4.8381],\n","        [ 6.4903, -4.8418],\n","        [ 6.3845, -4.7697],\n","        [ 6.4584, -4.8262],\n","        [-5.7449,  4.6642],\n","        [ 6.4306, -4.7998],\n","        [ 6.4481, -4.8228],\n","        [ 6.4329, -4.8246]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  4\n","batch:  [tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0])]\n","inputids tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(2.0772e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.8001,  4.7075],\n","        [-5.7671,  4.6891],\n","        [ 6.4820, -4.8434],\n","        [ 6.4468, -4.8344],\n","        [-5.7347,  4.6150],\n","        [ 6.3681, -4.7528],\n","        [ 6.4377, -4.8244],\n","        [-5.7145,  4.6292],\n","        [ 6.4007, -4.8128],\n","        [ 6.3246, -4.7511],\n","        [ 6.4514, -4.8474],\n","        [ 6.4315, -4.8147],\n","        [-5.7698,  4.6907],\n","        [-5.6729,  4.5913],\n","        [-5.7763,  4.6747],\n","        [ 6.4255, -4.8213]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  5\n","batch:  [tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1])]\n","inputids tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([10, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([10, 256])\n","labels:  tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n","labels:  torch.Size([10])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.7321e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.3222, -4.7443],\n","        [-5.7390,  4.6535],\n","        [ 6.4664, -4.8599],\n","        [ 6.4370, -4.8124],\n","        [ 6.4441, -4.8264],\n","        [-5.8491,  4.7164],\n","        [ 6.5264, -4.8851],\n","        [ 6.4232, -4.8091],\n","        [ 6.4714, -4.8548],\n","        [-5.8144,  4.7036]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([10, 2])\n","Accuracy: 1.0000\n"," F1 score: 1.0000\n"," Average training loss: 0.0000\n","Running Validation...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea2795d79470414ab03bea3e4a0d4bef"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":[" Accuracy: 0.8000\n"," F1 score: 0.7619\n","================= Epoch 10 / 15 =====================\n","Training ... \n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/6 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b548fa98bb24e2988d4bb43598a12b9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["step:  0\n","batch:  [tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])]\n","inputids tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.4335e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.5159, -4.8814],\n","        [ 6.5083, -4.8600],\n","        [ 6.4443, -4.8289],\n","        [ 6.5150, -4.8824],\n","        [-5.7752,  4.6588],\n","        [-5.8183,  4.7168],\n","        [ 6.5771, -4.9271],\n","        [-5.8823,  4.7638],\n","        [ 6.4896, -4.8769],\n","        [ 6.4585, -4.8520],\n","        [ 6.4479, -4.8101],\n","        [ 6.4756, -4.8730],\n","        [ 6.4786, -4.8801],\n","        [ 6.5440, -4.9051],\n","        [ 6.5609, -4.9163],\n","        [ 6.4947, -4.8825]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  1\n","batch:  [tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1])]\n","inputids tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.9833e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.8149,  4.7101],\n","        [-5.8054,  4.6979],\n","        [ 6.4932, -4.8756],\n","        [ 6.5867, -4.9289],\n","        [-5.7961,  4.6965],\n","        [-5.8564,  4.7360],\n","        [-5.7883,  4.6915],\n","        [ 6.5342, -4.8838],\n","        [ 6.4726, -4.8230],\n","        [ 6.4892, -4.8652],\n","        [ 6.3628, -4.7713],\n","        [ 6.5441, -4.9248],\n","        [-5.8029,  4.6933],\n","        [-5.8950,  4.7628],\n","        [-5.8532,  4.7279],\n","        [-5.8806,  4.7690]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  2\n","batch:  [tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1])]\n","inputids tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.7524e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.8264,  4.7054],\n","        [ 6.5065, -4.8592],\n","        [-5.9064,  4.7640],\n","        [ 6.5551, -4.9013],\n","        [ 6.5147, -4.8865],\n","        [ 6.5541, -4.9107],\n","        [ 6.3763, -4.7720],\n","        [ 6.4659, -4.8365],\n","        [ 6.4234, -4.8128],\n","        [-5.8142,  4.7120],\n","        [-5.7688,  4.6581],\n","        [ 6.5187, -4.8890],\n","        [ 6.5250, -4.9005],\n","        [-5.7957,  4.6886],\n","        [ 6.5108, -4.8590],\n","        [-5.8053,  4.6647]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  3\n","batch:  [tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0])]\n","inputids tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.3746e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.5186, -4.8911],\n","        [ 6.4794, -4.8697],\n","        [-5.8758,  4.7728],\n","        [ 6.5617, -4.9130],\n","        [ 6.5494, -4.9004],\n","        [ 6.4520, -4.8328],\n","        [ 6.5216, -4.8888],\n","        [-5.8871,  4.7617],\n","        [ 6.4642, -4.8461],\n","        [ 6.4748, -4.8477],\n","        [ 6.4833, -4.8514],\n","        [ 6.4972, -4.8745],\n","        [-5.8332,  4.7355],\n","        [ 6.5337, -4.9086],\n","        [ 6.5467, -4.8992],\n","        [ 6.5697, -4.9374]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  4\n","batch:  [tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0])]\n","inputids tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.7173e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.8075,  4.7219],\n","        [-5.8736,  4.7547],\n","        [ 6.4397, -4.8458],\n","        [ 6.5631, -4.9098],\n","        [-5.7981,  4.7056],\n","        [ 6.5010, -4.8722],\n","        [ 6.5870, -4.9562],\n","        [-5.8489,  4.7395],\n","        [ 6.5186, -4.8790],\n","        [ 6.5487, -4.9304],\n","        [ 6.5479, -4.8801],\n","        [ 6.5473, -4.9023],\n","        [-5.8483,  4.7420],\n","        [-5.8667,  4.7465],\n","        [-5.8919,  4.7473],\n","        [ 6.5391, -4.9143]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  5\n","batch:  [tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1])]\n","inputids tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([10, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([10, 256])\n","labels:  tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n","labels:  torch.Size([10])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.5139e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.5277, -4.9067],\n","        [-5.9062,  4.7738],\n","        [ 6.5078, -4.8798],\n","        [ 6.5900, -4.9573],\n","        [ 6.4545, -4.8422],\n","        [-5.8429,  4.7329],\n","        [ 6.5171, -4.8969],\n","        [ 6.5510, -4.9234],\n","        [ 6.4816, -4.8570],\n","        [-5.8405,  4.7475]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([10, 2])\n","Accuracy: 1.0000\n"," F1 score: 1.0000\n"," Average training loss: 0.0000\n","Running Validation...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd66982c6bb848fba1dbecd15fd0785d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":[" Accuracy: 0.8000\n"," F1 score: 0.7619\n","================= Epoch 11 / 15 =====================\n","Training ... \n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/6 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4123b0c09eef41529bb174429cae46df"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["step:  0\n","batch:  [tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])]\n","inputids tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.3672e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.5960, -4.9524],\n","        [ 6.5403, -4.8802],\n","        [ 6.4873, -4.8536],\n","        [ 6.5781, -4.9268],\n","        [-5.8329,  4.7188],\n","        [-5.8410,  4.7355],\n","        [ 6.5361, -4.8935],\n","        [-5.9166,  4.7867],\n","        [ 6.4964, -4.8699],\n","        [ 6.4891, -4.8935],\n","        [ 6.4944, -4.8808],\n","        [ 6.4620, -4.8428],\n","        [ 6.5156, -4.8807],\n","        [ 6.5708, -4.9395],\n","        [ 6.5280, -4.8909],\n","        [ 6.4677, -4.8545]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  1\n","batch:  [tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1])]\n","inputids tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.8567e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.9246,  4.8029],\n","        [-5.8094,  4.7153],\n","        [ 6.4960, -4.8807],\n","        [ 6.4888, -4.8877],\n","        [-5.9217,  4.8088],\n","        [-5.8662,  4.7462],\n","        [-5.8362,  4.7288],\n","        [ 6.5127, -4.9102],\n","        [ 6.5409, -4.9161],\n","        [ 6.6052, -4.9547],\n","        [ 6.3760, -4.7625],\n","        [ 6.5525, -4.9196],\n","        [-5.8609,  4.7403],\n","        [-5.9227,  4.7980],\n","        [-5.8161,  4.6977],\n","        [-5.9174,  4.7587]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  2\n","batch:  [tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1])]\n","inputids tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.6041e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.8511,  4.7338],\n","        [ 6.5627, -4.9135],\n","        [-5.8596,  4.7772],\n","        [ 6.6233, -4.9714],\n","        [ 6.5409, -4.9247],\n","        [ 6.4303, -4.8341],\n","        [ 6.5398, -4.9141],\n","        [ 6.5642, -4.9317],\n","        [ 6.6123, -4.9597],\n","        [-5.8193,  4.7448],\n","        [-5.8587,  4.7398],\n","        [ 6.5658, -4.9297],\n","        [ 6.4865, -4.8509],\n","        [-5.8133,  4.6934],\n","        [ 6.4620, -4.8579],\n","        [-5.9325,  4.7914]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  3\n","batch:  [tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0])]\n","inputids tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.3046e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.6018, -4.9624],\n","        [ 6.5256, -4.8943],\n","        [-5.8098,  4.7284],\n","        [ 6.5924, -4.9509],\n","        [ 6.5491, -4.9408],\n","        [ 6.5434, -4.9114],\n","        [ 6.5342, -4.9003],\n","        [-5.9021,  4.7892],\n","        [ 6.4841, -4.8803],\n","        [ 6.5252, -4.9198],\n","        [ 6.5608, -4.9167],\n","        [ 6.5858, -4.9180],\n","        [-5.9543,  4.8039],\n","        [ 6.4531, -4.8288],\n","        [ 6.5408, -4.9146],\n","        [ 6.5402, -4.9366]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  4\n","batch:  [tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0])]\n","inputids tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.5721e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.9170,  4.7981],\n","        [-5.8903,  4.7789],\n","        [ 6.6107, -4.9551],\n","        [ 6.5259, -4.9018],\n","        [-5.9307,  4.8135],\n","        [ 6.6167, -4.9393],\n","        [ 6.5922, -4.9344],\n","        [-5.9082,  4.8013],\n","        [ 6.5719, -4.9590],\n","        [ 6.4772, -4.8543],\n","        [ 6.6417, -4.9951],\n","        [ 6.6167, -4.9696],\n","        [-5.8145,  4.7162],\n","        [-5.8705,  4.7757],\n","        [-5.9176,  4.7820],\n","        [ 6.6058, -4.9714]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  5\n","batch:  [tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1])]\n","inputids tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([10, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([10, 256])\n","labels:  tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n","labels:  torch.Size([10])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.4460e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.5188, -4.8950],\n","        [-5.9092,  4.7755],\n","        [ 6.4960, -4.8932],\n","        [ 6.5854, -4.9478],\n","        [ 6.4513, -4.8572],\n","        [-5.8123,  4.7532],\n","        [ 6.5852, -4.9584],\n","        [ 6.5937, -4.9381],\n","        [ 6.5391, -4.9182],\n","        [-5.9404,  4.8072]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([10, 2])\n","Accuracy: 1.0000\n"," F1 score: 1.0000\n"," Average training loss: 0.0000\n","Running Validation...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6f490af1c6540088f86e13d59c23a32"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":[" Accuracy: 0.8000\n"," F1 score: 0.7619\n","================= Epoch 12 / 15 =====================\n","Training ... \n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/6 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"777ede93d031476f83c5603053bd3739"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["step:  0\n","batch:  [tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])]\n","inputids tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.2159e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.6636, -5.0292],\n","        [ 6.5416, -4.9273],\n","        [ 6.6002, -4.9647],\n","        [ 6.5370, -4.9193],\n","        [-5.9328,  4.8007],\n","        [-5.9189,  4.7932],\n","        [ 6.6060, -4.9544],\n","        [-5.9329,  4.8181],\n","        [ 6.5875, -4.9322],\n","        [ 6.5645, -4.9312],\n","        [ 6.5017, -4.8792],\n","        [ 6.5914, -4.9390],\n","        [ 6.5604, -4.9047],\n","        [ 6.6306, -4.9804],\n","        [ 6.6012, -4.9228],\n","        [ 6.5945, -4.9363]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  1\n","batch:  [tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1])]\n","inputids tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(3.7063e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.9260,  4.8046],\n","        [-5.8925,  4.7940],\n","        [ 6.6075, -4.9701],\n","        [ 6.5455, -4.9283],\n","        [-5.9617,  4.8148],\n","        [-5.9272,  4.7844],\n","        [-5.8690,  4.7381],\n","        [ 6.5720, -4.9468],\n","        [ 6.4782, -4.8987],\n","        [ 6.5547, -4.9083],\n","        [ 6.6170, -4.9836],\n","        [ 4.6583, -3.3506],\n","        [-5.8769,  4.7466],\n","        [-6.0570,  4.9191],\n","        [-5.8740,  4.7585],\n","        [-5.9271,  4.8119]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  2\n","batch:  [tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1])]\n","inputids tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.4901e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.9049,  4.7772],\n","        [ 6.5816, -4.9508],\n","        [-5.8558,  4.7644],\n","        [ 6.5430, -4.9325],\n","        [ 6.6606, -5.0033],\n","        [ 6.5834, -4.9471],\n","        [ 6.5308, -4.8927],\n","        [ 6.5717, -4.9195],\n","        [ 6.5848, -4.9499],\n","        [-5.8236,  4.7248],\n","        [-6.0067,  4.8532],\n","        [ 6.6086, -4.9616],\n","        [ 6.5828, -4.9307],\n","        [-5.8452,  4.7518],\n","        [ 6.5745, -4.9138],\n","        [-5.9317,  4.8224]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  3\n","batch:  [tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0])]\n","inputids tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.1392e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.6180, -4.9720],\n","        [ 6.6113, -4.9719],\n","        [-5.9123,  4.7744],\n","        [ 6.6137, -4.9821],\n","        [ 6.6556, -5.0107],\n","        [ 6.5652, -4.9479],\n","        [ 6.5669, -4.9335],\n","        [-6.0275,  4.8684],\n","        [ 6.5617, -4.9279],\n","        [ 6.6073, -4.9630],\n","        [ 6.5758, -4.9386],\n","        [ 6.6503, -5.0117],\n","        [-5.9728,  4.8219],\n","        [ 6.6789, -5.0127],\n","        [ 6.6774, -5.0236],\n","        [ 6.6297, -4.9907]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  4\n","batch:  [tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0])]\n","inputids tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.4454e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.9905,  4.8654],\n","        [-5.9621,  4.8094],\n","        [ 6.6232, -4.9923],\n","        [ 6.6479, -4.9815],\n","        [-5.9631,  4.8537],\n","        [ 6.5427, -4.9062],\n","        [ 6.5852, -4.9398],\n","        [-5.9716,  4.8281],\n","        [ 6.5417, -4.9051],\n","        [ 6.5186, -4.8847],\n","        [ 6.6394, -4.9800],\n","        [ 6.6532, -4.9869],\n","        [-5.9212,  4.8090],\n","        [-5.9052,  4.7828],\n","        [-6.0189,  4.8855],\n","        [ 6.6131, -4.9717]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  5\n","batch:  [tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1])]\n","inputids tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([10, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([10, 256])\n","labels:  tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n","labels:  torch.Size([10])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.2326e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.6577, -5.0116],\n","        [-5.9496,  4.8315],\n","        [ 6.5766, -4.9613],\n","        [ 6.6234, -4.9849],\n","        [ 6.5996, -4.9525],\n","        [-5.9590,  4.8509],\n","        [ 6.6877, -5.0174],\n","        [ 6.5772, -4.9771],\n","        [ 6.6673, -5.0078],\n","        [-5.9996,  4.8672]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([10, 2])\n","Accuracy: 1.0000\n"," F1 score: 1.0000\n"," Average training loss: 0.0000\n","Running Validation...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db6dceec189e4ae19c05c9da3cd619e7"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":[" Accuracy: 1.0000\n"," F1 score: 1.0000\n","Saved model to /content/drive/MyDrive\n","================= Epoch 13 / 15 =====================\n","Training ... \n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/6 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4c51e8c0bd74a238539c3e31f4dace0"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["step:  0\n","batch:  [tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])]\n","inputids tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.1757e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.5386, -4.9293],\n","        [ 6.6109, -4.9542],\n","        [ 6.5186, -4.8729],\n","        [ 6.6199, -4.9792],\n","        [-5.9046,  4.8056],\n","        [-6.0010,  4.8545],\n","        [ 6.6430, -5.0005],\n","        [-5.9779,  4.8299],\n","        [ 6.6083, -4.9569],\n","        [ 6.5750, -4.9413],\n","        [ 6.5260, -4.9154],\n","        [ 6.6385, -4.9749],\n","        [ 6.5514, -4.9245],\n","        [ 6.5442, -4.9432],\n","        [ 6.7027, -5.0465],\n","        [ 6.6289, -4.9798]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  1\n","batch:  [tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1])]\n","inputids tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.5385e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.0046,  4.8594],\n","        [-5.9959,  4.8468],\n","        [ 6.6389, -5.0039],\n","        [ 6.6160, -4.9545],\n","        [-5.9531,  4.8411],\n","        [-6.0024,  4.8552],\n","        [-5.9753,  4.8462],\n","        [ 6.6568, -4.9898],\n","        [ 6.5956, -4.9576],\n","        [ 6.6560, -4.9876],\n","        [ 6.6473, -4.9951],\n","        [ 6.5610, -4.9450],\n","        [-5.9114,  4.7914],\n","        [-6.0007,  4.8755],\n","        [-5.9162,  4.7922],\n","        [-5.9853,  4.8564]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  2\n","batch:  [tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1])]\n","inputids tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.3292e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.9075,  4.8149],\n","        [ 6.4964, -4.8811],\n","        [-5.9288,  4.8217],\n","        [ 6.6084, -4.9857],\n","        [ 6.6884, -5.0357],\n","        [ 6.7151, -5.0455],\n","        [ 6.5874, -4.9530],\n","        [ 6.6664, -4.9959],\n","        [ 6.6815, -5.0348],\n","        [-5.9375,  4.8020],\n","        [-6.0262,  4.8918],\n","        [ 6.5852, -4.9569],\n","        [ 6.5802, -4.9636],\n","        [-5.9780,  4.8348],\n","        [ 6.6218, -4.9866],\n","        [-6.0380,  4.8953]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  3\n","batch:  [tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0])]\n","inputids tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.3105e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.5706, -4.9226],\n","        [ 6.7113, -5.0617],\n","        [-5.9687,  4.8648],\n","        [ 6.6130, -4.9779],\n","        [ 6.6986, -5.0554],\n","        [ 6.5327, -4.9186],\n","        [ 6.6252, -4.9977],\n","        [-5.4447,  4.4429],\n","        [ 6.6332, -4.9729],\n","        [ 6.7610, -5.0672],\n","        [ 6.5589, -4.9243],\n","        [ 6.6330, -4.9975],\n","        [-5.9396,  4.8130],\n","        [ 6.6069, -4.9731],\n","        [ 6.6123, -4.9781],\n","        [ 6.6167, -4.9970]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  4\n","batch:  [tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0])]\n","inputids tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.4312e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.8991,  4.7907],\n","        [-5.9793,  4.8582],\n","        [ 6.6189, -4.9694],\n","        [ 6.6036, -4.9783],\n","        [-5.9691,  4.8375],\n","        [ 6.6337, -4.9743],\n","        [ 6.5918, -4.9759],\n","        [-5.9979,  4.8677],\n","        [ 6.6016, -4.9669],\n","        [ 6.5953, -4.9759],\n","        [ 6.6700, -5.0108],\n","        [ 6.6505, -5.0194],\n","        [-5.7583,  4.6678],\n","        [-6.0025,  4.8799],\n","        [-6.0151,  4.9071],\n","        [ 6.7183, -5.0445]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  5\n","batch:  [tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1])]\n","inputids tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([10, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([10, 256])\n","labels:  tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n","labels:  torch.Size([10])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.2362e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.6548, -5.0114],\n","        [-5.9971,  4.8656],\n","        [ 6.5181, -4.9081],\n","        [ 6.7079, -5.0443],\n","        [ 6.5615, -4.9518],\n","        [-6.0721,  4.9179],\n","        [ 6.5513, -4.9354],\n","        [ 6.5472, -4.9279],\n","        [ 6.6176, -4.9896],\n","        [-5.9581,  4.8391]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([10, 2])\n","Accuracy: 1.0000\n"," F1 score: 1.0000\n"," Average training loss: 0.0000\n","Running Validation...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"012a1fbe10534d7d94c4f958efe15e6f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":[" Accuracy: 0.9000\n"," F1 score: 0.8039\n","================= Epoch 14 / 15 =====================\n","Training ... \n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/6 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8201bf23e03c4408b6da739b55003b2c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["step:  0\n","batch:  [tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])]\n","inputids tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.0416e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.6985, -5.0401],\n","        [ 6.6912, -5.0477],\n","        [ 6.6448, -4.9955],\n","        [ 6.6205, -4.9918],\n","        [-6.0196,  4.8620],\n","        [-6.0501,  4.9147],\n","        [ 6.7094, -5.0511],\n","        [-6.0600,  4.9111],\n","        [ 6.6940, -5.0247],\n","        [ 6.5726, -4.9612],\n","        [ 6.6433, -4.9823],\n","        [ 6.6806, -5.0393],\n","        [ 6.5606, -4.9634],\n","        [ 6.5702, -4.9391],\n","        [ 6.6377, -4.9628],\n","        [ 6.7092, -5.0631]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  1\n","batch:  [tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1])]\n","inputids tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.5490e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.7996,  4.6944],\n","        [-6.0651,  4.9255],\n","        [ 6.6506, -5.0127],\n","        [ 6.6834, -5.0218],\n","        [-6.0070,  4.8997],\n","        [-6.0550,  4.9046],\n","        [-5.9851,  4.8555],\n","        [ 6.6266, -4.9924],\n","        [ 6.6284, -4.9857],\n","        [ 6.6532, -5.0311],\n","        [ 6.7523, -5.0710],\n","        [ 6.5708, -4.9603],\n","        [-5.9965,  4.8488],\n","        [-5.9351,  4.8027],\n","        [-5.8946,  4.7656],\n","        [-5.9049,  4.7805]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  2\n","batch:  [tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1])]\n","inputids tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(0.1163, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.9902,  4.8715],\n","        [ 6.6381, -5.0126],\n","        [-5.8476,  4.7412],\n","        [ 6.5745, -4.9612],\n","        [ 6.6375, -5.0161],\n","        [ 6.6385, -5.0048],\n","        [ 6.5668, -4.9250],\n","        [ 6.6795, -5.0059],\n","        [ 6.6800, -5.0586],\n","        [-6.0372,  4.8914],\n","        [-6.0173,  4.8872],\n","        [ 6.6623, -5.0071],\n","        [ 6.6386, -4.9839],\n","        [-5.9760,  4.8420],\n","        [ 6.6511, -5.0225],\n","        [ 0.9730, -0.7192]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  3\n","batch:  [tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0])]\n","inputids tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.0975e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.7228, -5.0672],\n","        [ 6.5562, -4.9444],\n","        [-5.9371,  4.8183],\n","        [ 6.6133, -4.9861],\n","        [ 6.6754, -5.0076],\n","        [ 6.7194, -5.0728],\n","        [ 6.6010, -4.9507],\n","        [-5.8977,  4.8348],\n","        [ 6.6663, -5.0368],\n","        [ 6.6855, -5.0404],\n","        [ 6.5814, -4.9469],\n","        [ 6.6625, -5.0290],\n","        [-5.9606,  4.8279],\n","        [ 6.6180, -4.9844],\n","        [ 6.6974, -5.0582],\n","        [ 6.7128, -5.0653]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  4\n","batch:  [tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0])]\n","inputids tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.2688e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.9794,  4.8387],\n","        [-6.0396,  4.8756],\n","        [ 6.6756, -5.0288],\n","        [ 6.6713, -5.0251],\n","        [-5.9455,  4.8551],\n","        [ 6.7466, -5.0666],\n","        [ 6.6932, -5.0397],\n","        [-5.9944,  4.8588],\n","        [ 6.6441, -4.9868],\n","        [ 6.6063, -4.9752],\n","        [ 6.6675, -5.0100],\n","        [ 6.7237, -5.0400],\n","        [-6.0634,  4.9173],\n","        [-6.0698,  4.9357],\n","        [-6.0799,  4.9395],\n","        [ 6.6470, -4.9962]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  5\n","batch:  [tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1])]\n","inputids tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([10, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([10, 256])\n","labels:  tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n","labels:  torch.Size([10])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.2040e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.7386, -5.0586],\n","        [-5.9116,  4.8195],\n","        [ 6.6004, -4.9464],\n","        [ 6.6771, -5.0445],\n","        [ 6.6886, -5.0249],\n","        [-5.9932,  4.8840],\n","        [ 6.6755, -5.0149],\n","        [ 6.6614, -5.0054],\n","        [ 6.6421, -5.0145],\n","        [-5.9492,  4.8413]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([10, 2])\n","Accuracy: 0.9896\n"," F1 score: 0.9885\n"," Average training loss: 0.0194\n","Running Validation...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94e78eb5ef2e45dea34be0de17bb2ec3"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":[" Accuracy: 0.8000\n"," F1 score: 0.7619\n","================= Epoch 15 / 15 =====================\n","Training ... \n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/6 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c820bb426109460b81073f6740958525"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["step:  0\n","batch:  [tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])]\n","inputids tensor([[    3,   292,   915,  ...,     1,     1,     1],\n","        [    3, 36157, 22143,  ...,     1,     1,     1],\n","        [    3,  2324,  1124,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 11759,   692,  ...,     1,     1,     1],\n","        [    3,  2479,  4104,  ...,     1,     1,     1],\n","        [    3,  1910,   311,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.0200e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.7198, -5.0706],\n","        [ 6.6742, -5.0387],\n","        [ 6.6757, -5.0360],\n","        [ 6.6510, -4.9857],\n","        [-5.9813,  4.8666],\n","        [-6.0153,  4.8724],\n","        [ 6.7441, -5.0575],\n","        [-5.9649,  4.8718],\n","        [ 6.6730, -5.0281],\n","        [ 6.6254, -5.0128],\n","        [ 6.6532, -4.9998],\n","        [ 6.6497, -5.0074],\n","        [ 6.7815, -5.1008],\n","        [ 6.7036, -5.0437],\n","        [ 6.6741, -5.0279],\n","        [ 6.7335, -5.0682]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  1\n","batch:  [tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1])]\n","inputids tensor([[    3, 15973,   216,  ...,     1,     1,     1],\n","        [    3, 10931, 24017,  ...,     1,     1,     1],\n","        [    3,    77,    24,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    97,   805,  ...,     1,     1,     1],\n","        [    3,   524,  1529,  ...,     1,     1,     1],\n","        [    3, 58605,  1387,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.4059e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.0379,  4.8973],\n","        [-5.9423,  4.7988],\n","        [ 6.6407, -4.9961],\n","        [ 6.7297, -5.0670],\n","        [-6.0145,  4.8927],\n","        [-6.0204,  4.9085],\n","        [-6.0296,  4.8957],\n","        [ 6.7244, -5.0548],\n","        [ 6.6422, -4.9886],\n","        [ 6.6364, -5.0025],\n","        [ 6.6918, -5.0171],\n","        [ 6.6880, -5.0072],\n","        [-6.0293,  4.8841],\n","        [-6.0114,  4.8844],\n","        [-6.0014,  4.8585],\n","        [-6.0638,  4.9060]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  2\n","batch:  [tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1])]\n","inputids tensor([[    3,   115,  2796,  ...,     1,     1,     1],\n","        [    3, 32284,  3950,  ...,     1,     1,     1],\n","        [    3,  7271,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3,    52,  2105,  ...,     1,     1,     1],\n","        [    3,    25,   214,  ...,     1,     1,     1],\n","        [    3,    83, 59763,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(0.6812, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.9792,  4.8401],\n","        [ 6.7368, -5.0809],\n","        [-5.9814,  4.8463],\n","        [ 6.6435, -5.0062],\n","        [ 6.1426, -4.5615],\n","        [ 6.6602, -5.0103],\n","        [-6.0201,  4.8791],\n","        [ 6.7249, -5.0574],\n","        [ 6.7794, -5.0873],\n","        [-6.0224,  4.9012],\n","        [-6.0889,  4.9311],\n","        [ 6.7328, -5.0604],\n","        [ 6.7179, -5.0673],\n","        [-5.9378,  4.8206],\n","        [ 6.7410, -5.0852],\n","        [-5.9911,  4.8207]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  3\n","batch:  [tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0])]\n","inputids tensor([[    3,   292,   514,  ...,     1,     1,     1],\n","        [    3,    26,    37,  ...,     1,     1,     1],\n","        [    3,    26,  7246,  ...,     1,     1,     1],\n","        ...,\n","        [    3,  1529, 27471,  ...,     1,     1,     1],\n","        [    3,    47,  8611,  ...,     1,     1,     1],\n","        [    3, 51497, 17680,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.0870e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.7314, -5.0618],\n","        [ 6.5448, -4.9342],\n","        [-5.8796,  4.7492],\n","        [ 6.6566, -5.0229],\n","        [ 6.6981, -5.0222],\n","        [ 6.7041, -5.0242],\n","        [ 6.7273, -5.0547],\n","        [-5.9841,  4.8537],\n","        [ 6.7065, -5.0339],\n","        [ 6.6856, -5.0137],\n","        [ 6.7065, -5.0479],\n","        [ 6.7062, -5.0326],\n","        [-5.9532,  4.8444],\n","        [ 6.5780, -4.9463],\n","        [ 6.6824, -5.0155],\n","        [ 6.6616, -4.9665]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  4\n","batch:  [tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0])]\n","inputids tensor([[    3,     8,   325,  ...,     1,     1,     1],\n","        [    3,  9105,   479,  ...,     1,     1,     1],\n","        [    3, 48277,    14,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 20758,    26,  ...,     1,     1,     1],\n","        [    3,  4189,  4335,  ...,     1,     1,     1],\n","        [    3,   457,     6,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([16, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([16, 256])\n","labels:  tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0], device='cuda:0')\n","labels:  torch.Size([16])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.6101e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.7655,  4.7080],\n","        [-5.6826,  4.5965],\n","        [ 6.6550, -5.0180],\n","        [ 6.6257, -4.9752],\n","        [-5.8676,  4.7545],\n","        [ 6.6419, -5.0025],\n","        [ 6.6334, -4.9799],\n","        [-5.9107,  4.7711],\n","        [ 6.6274, -4.9990],\n","        [ 6.6261, -4.9824],\n","        [ 6.5904, -4.9404],\n","        [ 6.6913, -5.0135],\n","        [-5.9061,  4.7970],\n","        [-5.8912,  4.7801],\n","        [-5.9224,  4.7885],\n","        [ 6.6934, -5.0342]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([16, 2])\n","step:  5\n","batch:  [tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1])]\n","inputids tensor([[    3, 50469, 62661,  ...,     1,     1,     1],\n","        [    3,   184,  1416,  ...,     1,     1,     1],\n","        [    3,  5016,     7,  ...,     1,     1,     1],\n","        ...,\n","        [    3, 15578,    71,  ...,     1,     1,     1],\n","        [    3, 14203, 10919,  ...,     1,     1,     1],\n","        [    3,  5608,   486,  ...,     1,     1,     1]], device='cuda:0')\n","inputids_shape torch.Size([10, 256])\n","mask:   tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","mask_shape:   torch.Size([10, 256])\n","labels:  tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n","labels:  torch.Size([10])\n","outputs:  SequenceClassifierOutput(loss=tensor(1.4412e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 6.5997, -4.9691],\n","        [-5.7560,  4.6580],\n","        [ 6.6113, -4.9543],\n","        [ 6.6108, -4.9827],\n","        [ 6.6791, -5.0234],\n","        [-5.8401,  4.7445],\n","        [ 6.6209, -4.9740],\n","        [ 6.6513, -5.0049],\n","        [ 6.6113, -4.9679],\n","        [-5.8412,  4.7487]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","outputs_shape:  torch.Size([10, 2])\n","Accuracy: 0.9896\n"," F1 score: 0.9892\n"," Average training loss: 0.1135\n","Running Validation...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cb8808b906646b2b12432eb762a2b09"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":[" Accuracy: 0.8000\n"," F1 score: 0.7619\n","Training complete!\n"]}],"source":["# định nghĩa tham số\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","epochs = 15\n","save_dir = '/content/drive/MyDrive'\n","best_acc = 0\n","\n","# lưu lại lịch sử\n","losses = []\n","train_accs = []\n","val_accs = []\n","\n","# define optimizer\n","param_optimizer = list(custom_model.named_parameters())\n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5, correct_bias=False)\n","\n","# Train theo từng epoch\n","for epoch_i in range(0, epochs):\n","  print('================= Epoch {} / {} ====================='.format(epoch_i + 1, epochs))\n","  print('Training ... ')\n","\n","  # Tham số train\n","  total_loss = 0\n","  custom_model.train()\n","  train_accuracy = 0\n","  nb_train_steps = 0\n","  train_f1 = 0\n","\n","  # Train từng batch\n","  for step, batch in enumerate(tqdm(train_dataloader)):\n","    b_input_ids = batch[0].to(device)\n","    b_input_mask = batch[1].to(device)\n","    b_labels = batch[2].to(device)\n","\n","    # check======\n","    print(\"step: \", step)\n","    print(\"batch: \" ,batch)\n","    print(\"inputids\" ,b_input_ids)\n","    print(\"inputids_shape\" ,b_input_ids.shape)\n","\n","    print(\"mask:  \", b_input_mask)\n","    print(\"mask_shape:  \", b_input_mask.shape)\n","\n","    print(\"labels: \", b_labels)\n","    print(\"labels: \", b_labels.shape)\n","    #======\n","\n","    custom_model.zero_grad()\n","    outputs = custom_model(\n","        b_input_ids,\n","        token_type_ids=None,\n","        attention_mask=b_input_mask,\n","        labels=b_labels\n","    )\n","\n","    #check====\n","    print(\"outputs: \" ,outputs)\n","    print(\"outputs_shape: \" ,outputs[1].shape)\n","\n","    #======\n","\n","    loss = outputs[0]\n","    total_loss += loss.item()\n","\n","    logits = outputs[1].detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","    tmp_train_accuracy, tmp_train_f1 = flat_accuracy(logits, label_ids)\n","    train_accuracy += tmp_train_accuracy\n","    train_f1 += tmp_train_f1\n","    nb_train_steps += 1\n","\n","    loss.backward()\n","    torch.nn.utils.clip_grad_norm_(custom_model.parameters(), 1.0)\n","    optimizer.step()\n","\n","  # tính average loss và accuracy cho epoch đó\n","  avg_train_loss = total_loss / len(train_dataloader)\n","  losses.append(avg_train_loss)\n","  train_accs.append(train_accuracy/nb_train_steps)\n","\n","  print('Accuracy: {0:.4f}'.format(train_accuracy/nb_train_steps))\n","  print(\" F1 score: {0:.4f}\".format(train_f1/nb_train_steps))\n","  print(\" Average training loss: {0:.4f}\".format(avg_train_loss))\n","\n","  print(\"Running Validation...\")\n","\n","  custom_model.eval()\n","\n","  # tham số validate\n","  eval_loss, eval_accuracy = 0, 0\n","  nb_eval_steps, nb_eval_examples = 0, 0\n","  eval_f1 = 0\n","\n","  # đánh giá\n","  for step, batch in enumerate(tqdm(val_dataloader)):\n","    b_input_ids = batch[0].to(device)\n","    b_input_mask = batch[1].to(device)\n","    b_labels = batch[2].to(device)\n","\n","    custom_model.zero_grad()\n","    outputs = custom_model(\n","        b_input_ids,\n","        token_type_ids=None,\n","        attention_mask=b_input_mask,\n","        labels=b_labels\n","    )\n","    loss = outputs[0]\n","    total_loss += loss.item()\n","\n","    logits = outputs[1].detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","    tmp_eval_accuracy, tmp_eval_f1 = flat_accuracy(logits, label_ids)\n","    eval_accuracy += tmp_eval_accuracy\n","    eval_f1 += tmp_eval_f1\n","    nb_eval_steps += 1\n","\n","\n","  avg_val_acc = eval_accuracy/nb_eval_steps\n","  val_accs.append(avg_val_acc)\n","  print(\" Accuracy: {0:.4f}\".format(avg_val_acc))\n","  print(\" F1 score: {0:.4f}\".format(eval_f1/nb_eval_steps))\n","\n","  # save checkpoint\n","  if avg_val_acc > best_acc:\n","    # save checkpoint\n","    print('Saved model to %s' %save_dir)\n","    custom_model.save_pretrained(save_dir)\n","\n","    best_acc = avg_val_acc\n","\n","  # early stopping\n","  # if epoch_i >= 4: # Khởi động 3 epochs\n","  #   if avg_val_acc < val_accs[-2]:\n","  #     # bị overfit\n","  #     print('Early stopping!')\n","  #     break\n","print(\"Training complete!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lPLxZeaHLhSN"},"outputs":[],"source":["# save_dir = '/content/drive/MyDrive/pRoBERTa/trained_module/rationale_selection'\n","# custom_model.save_pretrained(save_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xs7-zUKWTJZZ"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"9e741afade0c43bea535ab16c233b455":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_863267402a304dfe94bd6606692313a1","IPY_MODEL_7ea0f6eb588d43f2b2b37de24063daec","IPY_MODEL_5c94014fceea46eaa6be4bf281b790aa"],"layout":"IPY_MODEL_22878c0b240e4dae9ce0e7ddc4d25990"}},"863267402a304dfe94bd6606692313a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_056ffb966c154cffaf93817aff2b72c5","placeholder":"​","style":"IPY_MODEL_68491a2219a244eab2999bfe2e4750fc","value":"Downloading (…)lve/main/config.json: 100%"}},"7ea0f6eb588d43f2b2b37de24063daec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d793fcbf8210455883c82399c2fcfbca","max":557,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3992630bbd9042098dc8e24d2939346c","value":557}},"5c94014fceea46eaa6be4bf281b790aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eaa925f268ef4e03812c8f1b86ef181a","placeholder":"​","style":"IPY_MODEL_901fbec481c841698cb7d087d087296a","value":" 557/557 [00:00&lt;00:00, 21.9kB/s]"}},"22878c0b240e4dae9ce0e7ddc4d25990":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"056ffb966c154cffaf93817aff2b72c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68491a2219a244eab2999bfe2e4750fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d793fcbf8210455883c82399c2fcfbca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3992630bbd9042098dc8e24d2939346c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eaa925f268ef4e03812c8f1b86ef181a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"901fbec481c841698cb7d087d087296a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aab96a30a8824fdc98937d8f39811b59":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3303595a38384063887575352d77e485","IPY_MODEL_a7c7b2f13e7a49ccac298e0f3d61fe41","IPY_MODEL_d82f5ce0e6c844ef969c37a7038fe81e"],"layout":"IPY_MODEL_cbe1094dc04140a9872b45813e65ca38"}},"3303595a38384063887575352d77e485":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90d9cfbb92be40ca96087c1312df5b69","placeholder":"​","style":"IPY_MODEL_274466cb93cb4eab92351af04ea00f62","value":"Downloading pytorch_model.bin: 100%"}},"a7c7b2f13e7a49ccac298e0f3d61fe41":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa7a49cc8a0a4726b3051fe08be93c85","max":542923308,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f482c215e806426abcd9e6cacd01f7b4","value":542923308}},"d82f5ce0e6c844ef969c37a7038fe81e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eda883c9b6954489a112e3e1e739dbb4","placeholder":"​","style":"IPY_MODEL_8ba87271333e41d7b000d8914f3e9590","value":" 543M/543M [00:02&lt;00:00, 246MB/s]"}},"cbe1094dc04140a9872b45813e65ca38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90d9cfbb92be40ca96087c1312df5b69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"274466cb93cb4eab92351af04ea00f62":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa7a49cc8a0a4726b3051fe08be93c85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f482c215e806426abcd9e6cacd01f7b4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eda883c9b6954489a112e3e1e739dbb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ba87271333e41d7b000d8914f3e9590":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7063d9a90d0f43589ba96604fad38c50":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_44df77f99dbb49e894580165657dcf2b","IPY_MODEL_0b912422cf96432c9cd5d4094b45f674","IPY_MODEL_7bf340da7a2f42ce93366bffaaedaf4d"],"layout":"IPY_MODEL_42f93dd648dd4adfad5331568c1bd467"}},"44df77f99dbb49e894580165657dcf2b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fc4958d31844f518edbd70786e1e92e","placeholder":"​","style":"IPY_MODEL_4278a0e3a11142deaa955c74dcf6614d","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"0b912422cf96432c9cd5d4094b45f674":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_549b0ce8164d432ebb45cad5ca1c67e6","max":895321,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dcf6df4b531c41238cb82c673a9ceea2","value":895321}},"7bf340da7a2f42ce93366bffaaedaf4d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_47a6ed8a543a47a699a7e181c1239e58","placeholder":"​","style":"IPY_MODEL_c6a2164e8d0b4feeb4107c4cbe513395","value":" 895k/895k [00:00&lt;00:00, 4.44MB/s]"}},"42f93dd648dd4adfad5331568c1bd467":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fc4958d31844f518edbd70786e1e92e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4278a0e3a11142deaa955c74dcf6614d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"549b0ce8164d432ebb45cad5ca1c67e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcf6df4b531c41238cb82c673a9ceea2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"47a6ed8a543a47a699a7e181c1239e58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6a2164e8d0b4feeb4107c4cbe513395":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72a4db38da374937ada94ddd84fe9bf2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4cb66dbb59154c218605854f672e5342","IPY_MODEL_0e8726dfb41645038a4217950ad70718","IPY_MODEL_9bd0bd2b4a2245679604966630be1442"],"layout":"IPY_MODEL_85566a0c4b0e46c7a9e36b0cb712b16b"}},"4cb66dbb59154c218605854f672e5342":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eed77b2e3a1140aa8c6e47a003d03d05","placeholder":"​","style":"IPY_MODEL_2b28c08a5ffa4383b6035410101cd0be","value":"Downloading (…)solve/main/bpe.codes: 100%"}},"0e8726dfb41645038a4217950ad70718":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_84e11e3cc864405abd6c2c2ea3d7cce6","max":1135173,"min":0,"orientation":"horizontal","style":"IPY_MODEL_969df808011545b08f342375351ea9dc","value":1135173}},"9bd0bd2b4a2245679604966630be1442":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_48622611962c4ed6a1a72466ec887a27","placeholder":"​","style":"IPY_MODEL_3549e084e2ef4b78b7e2c0c2cf0b66df","value":" 1.14M/1.14M [00:00&lt;00:00, 3.48MB/s]"}},"85566a0c4b0e46c7a9e36b0cb712b16b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eed77b2e3a1140aa8c6e47a003d03d05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b28c08a5ffa4383b6035410101cd0be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84e11e3cc864405abd6c2c2ea3d7cce6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"969df808011545b08f342375351ea9dc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"48622611962c4ed6a1a72466ec887a27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3549e084e2ef4b78b7e2c0c2cf0b66df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d0129ddcb6a3414cbf86b6546f085efb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c7a55b3bef7d44e38cb3a667626232c1","IPY_MODEL_cc32f484bb1e40c1b1fd3aef495ade44","IPY_MODEL_4f92b7bcc97f4109a0e57e674f308f47"],"layout":"IPY_MODEL_b699c1d8376a40f7859867a362fecc1c"}},"c7a55b3bef7d44e38cb3a667626232c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6dcc83daf8140ff950e097ff0b941f2","placeholder":"​","style":"IPY_MODEL_59d5c5ef4e9341799501e43bd88c0aa2","value":"Downloading (…)/main/tokenizer.json: 100%"}},"cc32f484bb1e40c1b1fd3aef495ade44":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7807ea36441a4c27a65d685807f1d02b","max":3132320,"min":0,"orientation":"horizontal","style":"IPY_MODEL_18434f6fce304203bb83a8510b04a05a","value":3132320}},"4f92b7bcc97f4109a0e57e674f308f47":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9180acf7335c4427a884021c50ce0725","placeholder":"​","style":"IPY_MODEL_0dd2f780c7e74e3bbf21864b6e900b7b","value":" 3.13M/3.13M [00:00&lt;00:00, 9.35MB/s]"}},"b699c1d8376a40f7859867a362fecc1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6dcc83daf8140ff950e097ff0b941f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59d5c5ef4e9341799501e43bd88c0aa2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7807ea36441a4c27a65d685807f1d02b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18434f6fce304203bb83a8510b04a05a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9180acf7335c4427a884021c50ce0725":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0dd2f780c7e74e3bbf21864b6e900b7b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36d9242d689248b0b33d850078a2ff7e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3fbcb080318748ca9747a83bdfa86c00","IPY_MODEL_bb806c3ca77b43dca5ccef3579321537","IPY_MODEL_ea39247f29704e93b981be6ecb4e1bff"],"layout":"IPY_MODEL_7e22faacd15e4bbc9e6c38698b33d92d"}},"3fbcb080318748ca9747a83bdfa86c00":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d550d5086b654fc2a54e68e06cadb4b1","placeholder":"​","style":"IPY_MODEL_bde4728b052d461eba75f74f07cd1d40","value":""}},"bb806c3ca77b43dca5ccef3579321537":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_63f3eee8ad5440c6a9bde03a355ab638","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1bb4b45e43a5411e9a4edb74cdcef108","value":1}},"ea39247f29704e93b981be6ecb4e1bff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8dc2095d91b4502816326bb7956d753","placeholder":"​","style":"IPY_MODEL_28d5af24ff424b52a7e24d338a81a03c","value":" 90/? [00:00&lt;00:00, 749.28it/s]"}},"7e22faacd15e4bbc9e6c38698b33d92d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d550d5086b654fc2a54e68e06cadb4b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bde4728b052d461eba75f74f07cd1d40":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63f3eee8ad5440c6a9bde03a355ab638":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"1bb4b45e43a5411e9a4edb74cdcef108":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f8dc2095d91b4502816326bb7956d753":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28d5af24ff424b52a7e24d338a81a03c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8cd56df5bbca4c50ad2203ef8b708372":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_308da933bf6a4a3a8bed558dfc4fcfea","IPY_MODEL_4942b37ff1c642daa39b68616605bdb1","IPY_MODEL_cf7cf0b2c11e4fff8284c439fc026ae2"],"layout":"IPY_MODEL_e913e0070fb14628acb31d4a36d467d0"}},"308da933bf6a4a3a8bed558dfc4fcfea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a31ca005a3dd493abd097df0d54fd9c2","placeholder":"​","style":"IPY_MODEL_83db8529a856485e9a5e20ecc41bdeac","value":""}},"4942b37ff1c642daa39b68616605bdb1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4087fa3431ef47258bb0bdb5d0b156ef","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_95389e8c32b14c8cb323a5ba02bdb799","value":1}},"cf7cf0b2c11e4fff8284c439fc026ae2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_969621ba6ecc402e94344b44ee7a0798","placeholder":"​","style":"IPY_MODEL_a45f5fd64bcb45acb16dfd4f6fd76a61","value":" 10/? [00:00&lt;00:00, 267.95it/s]"}},"e913e0070fb14628acb31d4a36d467d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a31ca005a3dd493abd097df0d54fd9c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83db8529a856485e9a5e20ecc41bdeac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4087fa3431ef47258bb0bdb5d0b156ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"95389e8c32b14c8cb323a5ba02bdb799":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"969621ba6ecc402e94344b44ee7a0798":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a45f5fd64bcb45acb16dfd4f6fd76a61":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd6531eea552430bbe5257b0aab09f66":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c59f9cbc7dc94e5b9d88752c64dc20c6","IPY_MODEL_5c0477d5f5bf405a871ff201a93fa591","IPY_MODEL_cf1c1bf844894bffb9b0c1421620c7b9"],"layout":"IPY_MODEL_80cd583431e04bf2b3526f75dc04b313"}},"c59f9cbc7dc94e5b9d88752c64dc20c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b25f4498b9064175aa9e01b3e20790cd","placeholder":"​","style":"IPY_MODEL_27f67f25560d433281b9de72e6216bc3","value":"100%"}},"5c0477d5f5bf405a871ff201a93fa591":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_28c9376680b54fc795a3aea180081551","max":6,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9e22f89e182c45c7b94ad14870ecdf39","value":6}},"cf1c1bf844894bffb9b0c1421620c7b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb0000bfa148475b80a8d01a22ac08b0","placeholder":"​","style":"IPY_MODEL_420391808246407eae87f8739496791d","value":" 6/6 [00:04&lt;00:00,  1.52it/s]"}},"80cd583431e04bf2b3526f75dc04b313":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b25f4498b9064175aa9e01b3e20790cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27f67f25560d433281b9de72e6216bc3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28c9376680b54fc795a3aea180081551":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e22f89e182c45c7b94ad14870ecdf39":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bb0000bfa148475b80a8d01a22ac08b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"420391808246407eae87f8739496791d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa615f53008a42d188734530fa2b7c23":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bdaca6711aa24d24abf921f25fddb919","IPY_MODEL_e0179dc91ffc44e198d39b353547e76a","IPY_MODEL_4d918a9bb7b24196a3a176be760df7a1"],"layout":"IPY_MODEL_de77b66d31174d47b68c11aad11393ab"}},"bdaca6711aa24d24abf921f25fddb919":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cdc0fd12d9cd41d294497f68d05e1d85","placeholder":"​","style":"IPY_MODEL_d10c371c37034ccd9215b4e9bda73640","value":"100%"}},"e0179dc91ffc44e198d39b353547e76a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1c8f679d5534252995fca479a02dae1","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e4a66d497ad44f958c3e7dd9d2102df4","value":1}},"4d918a9bb7b24196a3a176be760df7a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd8c4909018b4fa7b0ce016f3e24e66e","placeholder":"​","style":"IPY_MODEL_f89dc380b62d44c28e965661881bd194","value":" 1/1 [00:00&lt;00:00,  5.36it/s]"}},"de77b66d31174d47b68c11aad11393ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdc0fd12d9cd41d294497f68d05e1d85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d10c371c37034ccd9215b4e9bda73640":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1c8f679d5534252995fca479a02dae1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4a66d497ad44f958c3e7dd9d2102df4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fd8c4909018b4fa7b0ce016f3e24e66e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f89dc380b62d44c28e965661881bd194":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fe97f5ea3dc3428d9724b448dd0a8cb4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_81f5cafccc334fc4afd007c913829529","IPY_MODEL_517e25070ca74d6e89120ce41ed56c58","IPY_MODEL_651fe9b779b24dd187a02140b7ea9645"],"layout":"IPY_MODEL_431bf69d3d1c4372b1f56e9ec38f487f"}},"81f5cafccc334fc4afd007c913829529":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa00c48fa3fc447eb24a79823eb08afc","placeholder":"​","style":"IPY_MODEL_2d2a66492f1d4d08909e9adaf638c9c3","value":"100%"}},"517e25070ca74d6e89120ce41ed56c58":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_14cfc430df2b4f7dbcc3d2c62ed030e8","max":6,"min":0,"orientation":"horizontal","style":"IPY_MODEL_48e5cca952b848249d923a9010c86f05","value":6}},"651fe9b779b24dd187a02140b7ea9645":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_213c043fbbd3499895050987d948e21d","placeholder":"​","style":"IPY_MODEL_c73a6223bf2e404f85f95d73036bfa29","value":" 6/6 [00:04&lt;00:00,  1.55it/s]"}},"431bf69d3d1c4372b1f56e9ec38f487f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa00c48fa3fc447eb24a79823eb08afc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d2a66492f1d4d08909e9adaf638c9c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14cfc430df2b4f7dbcc3d2c62ed030e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48e5cca952b848249d923a9010c86f05":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"213c043fbbd3499895050987d948e21d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c73a6223bf2e404f85f95d73036bfa29":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d11d8eb79e5e4bd78e1b68bdbdb61ad5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c4ab26d9218466d972eebb6952e07c0","IPY_MODEL_f4a1be0092cf422aaab8242e56bae167","IPY_MODEL_aa503debe10546fa97acd842cd7ed301"],"layout":"IPY_MODEL_8ebe6b0ebd3b4da486c9e65dda6e781b"}},"9c4ab26d9218466d972eebb6952e07c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fa2e602263c470192429f73decf9b26","placeholder":"​","style":"IPY_MODEL_a9211bdd48f54f21b134e63696de6566","value":"100%"}},"f4a1be0092cf422aaab8242e56bae167":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a41ac9e36514a0abdc73449403c078a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2b36d5db6cd641a48a1cfff73acba508","value":1}},"aa503debe10546fa97acd842cd7ed301":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4eb39b3f270f44ff94af0ece36ea5fd9","placeholder":"​","style":"IPY_MODEL_fa9846c4975f4775ba79e664a60eaeea","value":" 1/1 [00:00&lt;00:00,  4.29it/s]"}},"8ebe6b0ebd3b4da486c9e65dda6e781b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fa2e602263c470192429f73decf9b26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9211bdd48f54f21b134e63696de6566":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a41ac9e36514a0abdc73449403c078a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b36d5db6cd641a48a1cfff73acba508":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4eb39b3f270f44ff94af0ece36ea5fd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa9846c4975f4775ba79e664a60eaeea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa0e20b020ff4db4aea99e927b8d107f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6e4bf2c21d634347ad5ea320fb480e82","IPY_MODEL_2a9371ee5b6d4daa80c0d238e6f5f5ef","IPY_MODEL_77132e3b8b744490bda812df63923a8e"],"layout":"IPY_MODEL_1299ea8d8fbd4721b625837ac5667584"}},"6e4bf2c21d634347ad5ea320fb480e82":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b685808635e429a8fbc72edad3bf1bd","placeholder":"​","style":"IPY_MODEL_fbfb09edc6744e63b892d6aea8dd1199","value":"100%"}},"2a9371ee5b6d4daa80c0d238e6f5f5ef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dadd3bf8ec7f42da80d2e299d030d690","max":6,"min":0,"orientation":"horizontal","style":"IPY_MODEL_648e5520e2b54c1faaccc4ecec88c8e9","value":6}},"77132e3b8b744490bda812df63923a8e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08f94daf3a78404c977b7ba44f678e44","placeholder":"​","style":"IPY_MODEL_c319b075a2714a1ebe198933a999daee","value":" 6/6 [00:04&lt;00:00,  1.56it/s]"}},"1299ea8d8fbd4721b625837ac5667584":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b685808635e429a8fbc72edad3bf1bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbfb09edc6744e63b892d6aea8dd1199":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dadd3bf8ec7f42da80d2e299d030d690":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"648e5520e2b54c1faaccc4ecec88c8e9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"08f94daf3a78404c977b7ba44f678e44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c319b075a2714a1ebe198933a999daee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0323a38c89144b408ef401b736f26837":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f49d5535e35f47f4a656a38901be7510","IPY_MODEL_108a96e56f514957850c3f7a0b4a2821","IPY_MODEL_9b214291bf3041adac5f91e8d87fa846"],"layout":"IPY_MODEL_2998081f536f44ac913d62f48c7d88d8"}},"f49d5535e35f47f4a656a38901be7510":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8870577f132b476eb414c1ffd9bcbfce","placeholder":"​","style":"IPY_MODEL_b0f43aaf814b4c26a79469a3a742f57d","value":"100%"}},"108a96e56f514957850c3f7a0b4a2821":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8816ab646adf42d7b574bb97872a1db8","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_637a1a4fd2f24858b7702b406142017f","value":1}},"9b214291bf3041adac5f91e8d87fa846":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f9e2fdbdcbe43558b6088176cbb0a01","placeholder":"​","style":"IPY_MODEL_8bfc211c431a4551a59d21fa064e09eb","value":" 1/1 [00:00&lt;00:00,  5.25it/s]"}},"2998081f536f44ac913d62f48c7d88d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8870577f132b476eb414c1ffd9bcbfce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0f43aaf814b4c26a79469a3a742f57d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8816ab646adf42d7b574bb97872a1db8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"637a1a4fd2f24858b7702b406142017f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f9e2fdbdcbe43558b6088176cbb0a01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bfc211c431a4551a59d21fa064e09eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"014217f6e5b24a338054c3ffb990f31f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9555e1a6212942ea97f504c141ca7459","IPY_MODEL_6432ae4447c84e69b230d8392a58f874","IPY_MODEL_58d5bdfd7bcd411aa4e12fed40cdd021"],"layout":"IPY_MODEL_8335648ae8e54a338c7bdd59e6fd4edd"}},"9555e1a6212942ea97f504c141ca7459":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_058eeeadf5a643558348c0e8d790e959","placeholder":"​","style":"IPY_MODEL_bd41846a42d54b85aaf08975636ec827","value":"100%"}},"6432ae4447c84e69b230d8392a58f874":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_02e8d2345e6a4df8a924cc9e5548d17b","max":6,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d2c37b295b564d419f8ba07fa38e532b","value":6}},"58d5bdfd7bcd411aa4e12fed40cdd021":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e4df21367c048f08e64a8af64833dba","placeholder":"​","style":"IPY_MODEL_faa133764afe42a69bb8fd38e57e9246","value":" 6/6 [00:04&lt;00:00,  1.55it/s]"}},"8335648ae8e54a338c7bdd59e6fd4edd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"058eeeadf5a643558348c0e8d790e959":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd41846a42d54b85aaf08975636ec827":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"02e8d2345e6a4df8a924cc9e5548d17b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2c37b295b564d419f8ba07fa38e532b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9e4df21367c048f08e64a8af64833dba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"faa133764afe42a69bb8fd38e57e9246":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f342c14a6f804e6f932f6a942bc2727e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a291af9479cc441ba03bce9dea2c9de0","IPY_MODEL_f5c3965f2f0f4bd1845da3d6f58d0f05","IPY_MODEL_b7b2b3eebdb145109279dfb6c6a7d9d8"],"layout":"IPY_MODEL_a7540caad920434a89ea4545a958486e"}},"a291af9479cc441ba03bce9dea2c9de0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_607f9d2a5e374463ad8d5f2991c2da35","placeholder":"​","style":"IPY_MODEL_ea24e3093fcd4b7ab568f85f9f70e70c","value":"100%"}},"f5c3965f2f0f4bd1845da3d6f58d0f05":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f9bec4bae084b8d8613f3da6a4a67fa","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_88fb58dae49d4ecf8dda0a6d4c63f6d9","value":1}},"b7b2b3eebdb145109279dfb6c6a7d9d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b26c810844e04871981bc3bc45caedc8","placeholder":"​","style":"IPY_MODEL_bc0c173327c54ee0988618c8523dc68a","value":" 1/1 [00:00&lt;00:00,  5.29it/s]"}},"a7540caad920434a89ea4545a958486e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"607f9d2a5e374463ad8d5f2991c2da35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea24e3093fcd4b7ab568f85f9f70e70c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f9bec4bae084b8d8613f3da6a4a67fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88fb58dae49d4ecf8dda0a6d4c63f6d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b26c810844e04871981bc3bc45caedc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc0c173327c54ee0988618c8523dc68a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4fcd7bea02d4d93ae344215eb243e58":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3fdd5a57c96f43648356418c41a0bd62","IPY_MODEL_a278e4f050af4bcdb1f71280f8a2eff7","IPY_MODEL_c56a111efa844052801ee11e83585047"],"layout":"IPY_MODEL_8f133f1d41cd4adf90ad433b57081cbe"}},"3fdd5a57c96f43648356418c41a0bd62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_276a589015c14e4a84f74c1c27e4957a","placeholder":"​","style":"IPY_MODEL_5272ed0b03fb43efa529256e99fdd1ed","value":"100%"}},"a278e4f050af4bcdb1f71280f8a2eff7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_24d53ff7d7724d43ae4ba4e4129fc710","max":6,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b82b8cf939674ac7bb03923cb2dd2e32","value":6}},"c56a111efa844052801ee11e83585047":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a18de690a91416ba5989027ad04c2d5","placeholder":"​","style":"IPY_MODEL_d82bfafbc533401ea968c14d53244ef4","value":" 6/6 [00:04&lt;00:00,  1.55it/s]"}},"8f133f1d41cd4adf90ad433b57081cbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"276a589015c14e4a84f74c1c27e4957a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5272ed0b03fb43efa529256e99fdd1ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24d53ff7d7724d43ae4ba4e4129fc710":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b82b8cf939674ac7bb03923cb2dd2e32":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7a18de690a91416ba5989027ad04c2d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d82bfafbc533401ea968c14d53244ef4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ef0d057a69c455bb7e097fa12733d73":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0d6920031e524ede83b04cc15a8bd7b3","IPY_MODEL_e9639de6b5eb47cdb5f5e716462faa5c","IPY_MODEL_7633b2ef1d4e46b080b06db58a60972a"],"layout":"IPY_MODEL_85cd89e62be247cea4ff70fea90f2aac"}},"0d6920031e524ede83b04cc15a8bd7b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f5324eff9d44d8eba0fdda395c4e85d","placeholder":"​","style":"IPY_MODEL_afd9bf03efb54313a053fdb9a794a14b","value":"100%"}},"e9639de6b5eb47cdb5f5e716462faa5c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e9d0836d5f048959239197721d79238","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_510270b697894664a1efbc7297f3ca03","value":1}},"7633b2ef1d4e46b080b06db58a60972a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_036af65e44f748279ea5b99c181e32ee","placeholder":"​","style":"IPY_MODEL_02e322a6436c480a9cb7e702d9336003","value":" 1/1 [00:00&lt;00:00,  6.32it/s]"}},"85cd89e62be247cea4ff70fea90f2aac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f5324eff9d44d8eba0fdda395c4e85d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afd9bf03efb54313a053fdb9a794a14b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e9d0836d5f048959239197721d79238":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"510270b697894664a1efbc7297f3ca03":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"036af65e44f748279ea5b99c181e32ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02e322a6436c480a9cb7e702d9336003":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a6fedbbb1c254d26a7949a0b8ffbf61f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_85edbb2b15c34881a895278c845894e4","IPY_MODEL_19e7cd7da791435aae99ff7099ecb587","IPY_MODEL_5ac26170c167439b8019c94d28b854b3"],"layout":"IPY_MODEL_acb99102e6914589aa6ea5526e1954a4"}},"85edbb2b15c34881a895278c845894e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19b33acb0c83473584bca3f15ac1f489","placeholder":"​","style":"IPY_MODEL_1b208b8ccb6e4687885bda7ba32c52d3","value":"100%"}},"19e7cd7da791435aae99ff7099ecb587":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d026fe664c5e440a92de524ce9d531c7","max":6,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9e18ffe12fe8432aadef7bf0817bbfbb","value":6}},"5ac26170c167439b8019c94d28b854b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c5e644c88bf4192b2951276959f7412","placeholder":"​","style":"IPY_MODEL_b48e2d39215344c5a76ce86bc540dbf9","value":" 6/6 [00:04&lt;00:00,  1.55it/s]"}},"acb99102e6914589aa6ea5526e1954a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19b33acb0c83473584bca3f15ac1f489":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b208b8ccb6e4687885bda7ba32c52d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d026fe664c5e440a92de524ce9d531c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e18ffe12fe8432aadef7bf0817bbfbb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8c5e644c88bf4192b2951276959f7412":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b48e2d39215344c5a76ce86bc540dbf9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89827b2bbb6f439f8884f1db8fb7f92e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_11b5ba2e4e014a20b2c467d95602a7ff","IPY_MODEL_8dfb70c141744bb384191efc91a768e6","IPY_MODEL_b8bde0a15a1e4b4ab399304ad2e447f1"],"layout":"IPY_MODEL_a13e71f5779044be88a1620f69280df4"}},"11b5ba2e4e014a20b2c467d95602a7ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c365b12ed9b14d1ebfb4a1ada74f000b","placeholder":"​","style":"IPY_MODEL_c15ea76ef8664ce89980e621800965b5","value":"100%"}},"8dfb70c141744bb384191efc91a768e6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a21d3228a4c43408a57a9fa888c4b46","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3ef87761e2834e64867a127bda9edd75","value":1}},"b8bde0a15a1e4b4ab399304ad2e447f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c8a772b52a64aaaacc7db3292361b97","placeholder":"​","style":"IPY_MODEL_7dfd88cff15448c69d5044c1386d23e7","value":" 1/1 [00:00&lt;00:00,  6.24it/s]"}},"a13e71f5779044be88a1620f69280df4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c365b12ed9b14d1ebfb4a1ada74f000b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c15ea76ef8664ce89980e621800965b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a21d3228a4c43408a57a9fa888c4b46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ef87761e2834e64867a127bda9edd75":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1c8a772b52a64aaaacc7db3292361b97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7dfd88cff15448c69d5044c1386d23e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ebde6c17a099484eb818784fe058e68d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4ceafd786ea64e3595352b9e4133060a","IPY_MODEL_fd95286255ec4e96898101e9f3a30c57","IPY_MODEL_4672525323124b2f8bb494dc76acc91e"],"layout":"IPY_MODEL_f1f18a7255e646de9f9ba618965a26a6"}},"4ceafd786ea64e3595352b9e4133060a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f276c4c0abbb42a8b813055d9bd8bf1f","placeholder":"​","style":"IPY_MODEL_0404907a0b47496c895976a20a431e71","value":"100%"}},"fd95286255ec4e96898101e9f3a30c57":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_92863eab38b74c9abdf8fb2b76a68028","max":6,"min":0,"orientation":"horizontal","style":"IPY_MODEL_667ec4221ede4f0f92c36f598b77f40e","value":6}},"4672525323124b2f8bb494dc76acc91e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b522b749102a4d2cbbad7b6168b5a455","placeholder":"​","style":"IPY_MODEL_c9b2d32786514b2cb183dd0026157f76","value":" 6/6 [00:04&lt;00:00,  1.54it/s]"}},"f1f18a7255e646de9f9ba618965a26a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f276c4c0abbb42a8b813055d9bd8bf1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0404907a0b47496c895976a20a431e71":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92863eab38b74c9abdf8fb2b76a68028":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"667ec4221ede4f0f92c36f598b77f40e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b522b749102a4d2cbbad7b6168b5a455":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9b2d32786514b2cb183dd0026157f76":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9dc9efa2fa04bd6a18c81ea56a25471":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1e7b089cb05849f1b9bf6ae267bf51ea","IPY_MODEL_4442610115ea476281e3b869f4c81416","IPY_MODEL_ff518d1b2cfa47429a05ca23f839f9ca"],"layout":"IPY_MODEL_61552b59a0a2463ebad9ca3220b6336e"}},"1e7b089cb05849f1b9bf6ae267bf51ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c005427ad1fc40699f59ad9502ab8b65","placeholder":"​","style":"IPY_MODEL_e69497161b384344b4f72e60fd961ddf","value":"100%"}},"4442610115ea476281e3b869f4c81416":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d086a200f0247edac81d7a7bda2f108","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2cfa612828fd4139aa00d877f72e2212","value":1}},"ff518d1b2cfa47429a05ca23f839f9ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2c3e12a859b4db68c9153b2c63c1e51","placeholder":"​","style":"IPY_MODEL_13d9207cee2846009094efbd7d29abe7","value":" 1/1 [00:00&lt;00:00,  6.08it/s]"}},"61552b59a0a2463ebad9ca3220b6336e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c005427ad1fc40699f59ad9502ab8b65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e69497161b384344b4f72e60fd961ddf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d086a200f0247edac81d7a7bda2f108":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cfa612828fd4139aa00d877f72e2212":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c2c3e12a859b4db68c9153b2c63c1e51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13d9207cee2846009094efbd7d29abe7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f886ec0dbaa0410ab78be1f545b2bd9a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_38b0b968e1b44743bc388c79f9e3b648","IPY_MODEL_a295f696e8ee4018bdbd7226b47243f2","IPY_MODEL_79bec756170845978be6ed55be9bfe65"],"layout":"IPY_MODEL_c57e7e9eba7f4ed1b306b137ec32b183"}},"38b0b968e1b44743bc388c79f9e3b648":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00815f55dd7c43f78722b4d866a127a2","placeholder":"​","style":"IPY_MODEL_3142e6ab1b0b46d793dc0a022413a302","value":"100%"}},"a295f696e8ee4018bdbd7226b47243f2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9b9eb130b7d462d84ac25d5fe3028b2","max":6,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a4c2eb6bd2dd481bad5baf173d313e02","value":6}},"79bec756170845978be6ed55be9bfe65":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_259310844b3f4b31a41cc86a6114b261","placeholder":"​","style":"IPY_MODEL_15aa6e2e3c414cd39bcd53c28479bb9f","value":" 6/6 [00:04&lt;00:00,  1.54it/s]"}},"c57e7e9eba7f4ed1b306b137ec32b183":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00815f55dd7c43f78722b4d866a127a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3142e6ab1b0b46d793dc0a022413a302":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9b9eb130b7d462d84ac25d5fe3028b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4c2eb6bd2dd481bad5baf173d313e02":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"259310844b3f4b31a41cc86a6114b261":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15aa6e2e3c414cd39bcd53c28479bb9f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03c310a76f2e4cd29faceb3e5212466e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4b8350107a3c4c8cab310a6bdaa39c87","IPY_MODEL_0455335ce2c04c93a558496af2044121","IPY_MODEL_56bdac6382954406be1faa61adc38618"],"layout":"IPY_MODEL_d189a0e025774675b1cca6fde427a884"}},"4b8350107a3c4c8cab310a6bdaa39c87":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f09f95783b4478caffbf6b496893779","placeholder":"​","style":"IPY_MODEL_310874658cd64941a9e6e3e1d9d14fe5","value":"100%"}},"0455335ce2c04c93a558496af2044121":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2bc632af0934239a264f0508c81243a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2448522aec6e4906b8ac4cb4ce3f5aee","value":1}},"56bdac6382954406be1faa61adc38618":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_afa6f9d0205148aa9a1914b58976eb32","placeholder":"​","style":"IPY_MODEL_8dd7f83b8e2a4069b524e011917a6e4c","value":" 1/1 [00:00&lt;00:00,  5.95it/s]"}},"d189a0e025774675b1cca6fde427a884":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f09f95783b4478caffbf6b496893779":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"310874658cd64941a9e6e3e1d9d14fe5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f2bc632af0934239a264f0508c81243a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2448522aec6e4906b8ac4cb4ce3f5aee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"afa6f9d0205148aa9a1914b58976eb32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8dd7f83b8e2a4069b524e011917a6e4c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d5f19f16c2f4411a9a69b898598cee3f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_93aa4a3b9424498989d6a5e5c6ada64f","IPY_MODEL_a4998f5ab946427b9ed75f4507e3df2b","IPY_MODEL_621c9d48afff49a58700ccaefd84f4c4"],"layout":"IPY_MODEL_e22ebf95623c47b5b334c91f6ed9a544"}},"93aa4a3b9424498989d6a5e5c6ada64f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3a2de64c88a4f16a0bc4088880a6fc9","placeholder":"​","style":"IPY_MODEL_c54a527c9c2c483485b0b87815068995","value":"100%"}},"a4998f5ab946427b9ed75f4507e3df2b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_171f511b77e944d2a7fe9eef72aa88d5","max":6,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c52cbfff3e90429d882d972b93bfcccd","value":6}},"621c9d48afff49a58700ccaefd84f4c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb2abbe7443348089a5dfacdb53a5ae4","placeholder":"​","style":"IPY_MODEL_b9bc198b26ec40ab8dcc4074663cd690","value":" 6/6 [00:04&lt;00:00,  1.55it/s]"}},"e22ebf95623c47b5b334c91f6ed9a544":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3a2de64c88a4f16a0bc4088880a6fc9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c54a527c9c2c483485b0b87815068995":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"171f511b77e944d2a7fe9eef72aa88d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c52cbfff3e90429d882d972b93bfcccd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eb2abbe7443348089a5dfacdb53a5ae4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9bc198b26ec40ab8dcc4074663cd690":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea2795d79470414ab03bea3e4a0d4bef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c32d7b14a2246328d09a6bc53108394","IPY_MODEL_e891ddeb227e4849b9e3f10fd375a6ca","IPY_MODEL_1d6059a9dbdf4bc996dad49247be5acf"],"layout":"IPY_MODEL_a068edd28f61459fbfbdd00e79a12ad2"}},"8c32d7b14a2246328d09a6bc53108394":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed7820dea7e842a681fcd54c6de7d9c2","placeholder":"​","style":"IPY_MODEL_34c13a9bf9d242cb973e96def1c5351b","value":"100%"}},"e891ddeb227e4849b9e3f10fd375a6ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9623e19644c54167a8280f05c8621148","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0d61326de9d04bc3b8acf1c442b7c5a5","value":1}},"1d6059a9dbdf4bc996dad49247be5acf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5473fc269ea746f88fc4e5134414ac72","placeholder":"​","style":"IPY_MODEL_64f113dfa090488d93e9be14f875b542","value":" 1/1 [00:00&lt;00:00,  6.08it/s]"}},"a068edd28f61459fbfbdd00e79a12ad2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed7820dea7e842a681fcd54c6de7d9c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34c13a9bf9d242cb973e96def1c5351b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9623e19644c54167a8280f05c8621148":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d61326de9d04bc3b8acf1c442b7c5a5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5473fc269ea746f88fc4e5134414ac72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64f113dfa090488d93e9be14f875b542":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b548fa98bb24e2988d4bb43598a12b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7f6a995e8cab40d19ab1424173c33f92","IPY_MODEL_398af8b8e01e4236aa0fd1241510c777","IPY_MODEL_a77ed7c6c4a64f0294efc574bb56d704"],"layout":"IPY_MODEL_9c40b1c7e8684679b32fd37a25701e5c"}},"7f6a995e8cab40d19ab1424173c33f92":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a65c3a80921348ff9b0018b563315e08","placeholder":"​","style":"IPY_MODEL_d45322e6753644b3aace55a57a899053","value":"100%"}},"398af8b8e01e4236aa0fd1241510c777":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_50e57b62a1ab48ff91dcc15d91b6e4c4","max":6,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d803fbb1bd4d42d4b96cc216f1f097e4","value":6}},"a77ed7c6c4a64f0294efc574bb56d704":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aac3c96bbef14990b23671953644d42d","placeholder":"​","style":"IPY_MODEL_9d639490509a426e98191ff7b76984bb","value":" 6/6 [00:04&lt;00:00,  1.54it/s]"}},"9c40b1c7e8684679b32fd37a25701e5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a65c3a80921348ff9b0018b563315e08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d45322e6753644b3aace55a57a899053":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"50e57b62a1ab48ff91dcc15d91b6e4c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d803fbb1bd4d42d4b96cc216f1f097e4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aac3c96bbef14990b23671953644d42d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d639490509a426e98191ff7b76984bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd66982c6bb848fba1dbecd15fd0785d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_afd7ad09688e468b966b2c08cb73d595","IPY_MODEL_5e0e9def4c9d496c9f96a63ef821692a","IPY_MODEL_e4dcdc88b8d74e23a4a5009cb642b416"],"layout":"IPY_MODEL_1b902e2b8486442b9464e6951b24a8c9"}},"afd7ad09688e468b966b2c08cb73d595":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ac46039643844d28ba2425721c8a5c9","placeholder":"​","style":"IPY_MODEL_5e35dde74c5d4924ae53c60c671a6f23","value":"100%"}},"5e0e9def4c9d496c9f96a63ef821692a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7bbb044b86b64e6fbaca9fc256854cef","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_09cab07e2aff42e48bc99d88da098cf4","value":1}},"e4dcdc88b8d74e23a4a5009cb642b416":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c290a7b65f64220a6051c4f06f276ac","placeholder":"​","style":"IPY_MODEL_0c0192fe9db542b5afa56c16c5036f64","value":" 1/1 [00:00&lt;00:00,  6.21it/s]"}},"1b902e2b8486442b9464e6951b24a8c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ac46039643844d28ba2425721c8a5c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e35dde74c5d4924ae53c60c671a6f23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7bbb044b86b64e6fbaca9fc256854cef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09cab07e2aff42e48bc99d88da098cf4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2c290a7b65f64220a6051c4f06f276ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c0192fe9db542b5afa56c16c5036f64":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4123b0c09eef41529bb174429cae46df":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1d5c6ad3806341d08a27d5b0ecf214b7","IPY_MODEL_17d7d7bc81914684b00144040f1bddff","IPY_MODEL_c16d2e66bd574470b2b837d9a5f6d7cb"],"layout":"IPY_MODEL_492130cb24fb477bad7e1fffe6933877"}},"1d5c6ad3806341d08a27d5b0ecf214b7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3e69ae168274f0b8d143b388f85ee83","placeholder":"​","style":"IPY_MODEL_73384ec56a8c4a8aabf3bd1e29f4a0d9","value":"100%"}},"17d7d7bc81914684b00144040f1bddff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c83b2a3317d4fa8a80464a8bd668c7f","max":6,"min":0,"orientation":"horizontal","style":"IPY_MODEL_41041a45484f4a1ebce88e91df9161e4","value":6}},"c16d2e66bd574470b2b837d9a5f6d7cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b79a8f3c4db740c9bb81f467df9cd0aa","placeholder":"​","style":"IPY_MODEL_4d66f6f0eb554de1b68aa422e7125ff4","value":" 6/6 [00:04&lt;00:00,  1.55it/s]"}},"492130cb24fb477bad7e1fffe6933877":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3e69ae168274f0b8d143b388f85ee83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73384ec56a8c4a8aabf3bd1e29f4a0d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c83b2a3317d4fa8a80464a8bd668c7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41041a45484f4a1ebce88e91df9161e4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b79a8f3c4db740c9bb81f467df9cd0aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d66f6f0eb554de1b68aa422e7125ff4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f6f490af1c6540088f86e13d59c23a32":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c6819a485c6b42618663bbd1d58516e2","IPY_MODEL_8d90262e5c5b44aead38b2b70c93290b","IPY_MODEL_a4206564cd204a76a54aa4ba61595717"],"layout":"IPY_MODEL_4285a7c0bfab4bf1a8589c9ea66d10ab"}},"c6819a485c6b42618663bbd1d58516e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33a7893ba7484a4b9bce3f1c89eaa07e","placeholder":"​","style":"IPY_MODEL_bd70ea5432414690b2d41f4aaa81f87e","value":"100%"}},"8d90262e5c5b44aead38b2b70c93290b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b109529f22b4f51856dc2b8e740cfc6","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_17017a7262164b5ebaa51594e785e7e9","value":1}},"a4206564cd204a76a54aa4ba61595717":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0d3465401604a6a8a1cb6917ac620b2","placeholder":"​","style":"IPY_MODEL_56c96a12c0f3466482c256739bc8a779","value":" 1/1 [00:00&lt;00:00,  6.17it/s]"}},"4285a7c0bfab4bf1a8589c9ea66d10ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33a7893ba7484a4b9bce3f1c89eaa07e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd70ea5432414690b2d41f4aaa81f87e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b109529f22b4f51856dc2b8e740cfc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17017a7262164b5ebaa51594e785e7e9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d0d3465401604a6a8a1cb6917ac620b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56c96a12c0f3466482c256739bc8a779":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"777ede93d031476f83c5603053bd3739":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_21c08e3d21b64824b05545094dae5feb","IPY_MODEL_62cec17a7f824891a5dbb98a9e2ad5ec","IPY_MODEL_dfeb8d170b394fe0a7a1b6877cdecf7e"],"layout":"IPY_MODEL_b1d8e8b63685477cb05389479434376b"}},"21c08e3d21b64824b05545094dae5feb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c99d585f6f4f4c0eb87837749f6503b4","placeholder":"​","style":"IPY_MODEL_d1f37f914d0d4df4815a3aacb82e7d05","value":"100%"}},"62cec17a7f824891a5dbb98a9e2ad5ec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0effb51c054c4ecbbc2536365d21acd3","max":6,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2096cf7091c6416dac93b85201ee2948","value":6}},"dfeb8d170b394fe0a7a1b6877cdecf7e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6714861289b544399c2d6d45d2b85a66","placeholder":"​","style":"IPY_MODEL_1ada06f0793e4e8bb02900a2125ebc45","value":" 6/6 [00:04&lt;00:00,  1.56it/s]"}},"b1d8e8b63685477cb05389479434376b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c99d585f6f4f4c0eb87837749f6503b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1f37f914d0d4df4815a3aacb82e7d05":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0effb51c054c4ecbbc2536365d21acd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2096cf7091c6416dac93b85201ee2948":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6714861289b544399c2d6d45d2b85a66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ada06f0793e4e8bb02900a2125ebc45":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db6dceec189e4ae19c05c9da3cd619e7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_55fc6f3dd47446c88ec9ad6e82b3e147","IPY_MODEL_bfb37f900edb44f39612d662f2e14388","IPY_MODEL_436b14f19a1b4429839c966f17f82519"],"layout":"IPY_MODEL_f76a7b2af9a1479c89de8e4f9035b9a0"}},"55fc6f3dd47446c88ec9ad6e82b3e147":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b29c87757ee46a797f8bb623465bd2c","placeholder":"​","style":"IPY_MODEL_e91c9c220b084d4dbe12efaa49569b0a","value":"100%"}},"bfb37f900edb44f39612d662f2e14388":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_75064be61f9c4894856b472c341ce1c5","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8fdc77e40d304edc9ca54b110b22fa70","value":1}},"436b14f19a1b4429839c966f17f82519":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b9f3709bef34bc480c7408355d7662d","placeholder":"​","style":"IPY_MODEL_84c287e808a6489c8547f07c06633ebf","value":" 1/1 [00:00&lt;00:00,  5.88it/s]"}},"f76a7b2af9a1479c89de8e4f9035b9a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b29c87757ee46a797f8bb623465bd2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e91c9c220b084d4dbe12efaa49569b0a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"75064be61f9c4894856b472c341ce1c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fdc77e40d304edc9ca54b110b22fa70":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2b9f3709bef34bc480c7408355d7662d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84c287e808a6489c8547f07c06633ebf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4c51e8c0bd74a238539c3e31f4dace0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4e99a1c9175a4a91a620561d328c8e63","IPY_MODEL_988b400176584890aff0e7e84d83a15d","IPY_MODEL_3c6ad6c61fa344debfd069d023dc9ec1"],"layout":"IPY_MODEL_76e802486bb9445e8c788b1159427bd4"}},"4e99a1c9175a4a91a620561d328c8e63":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ff67574f03d40ebb646150436a4b207","placeholder":"​","style":"IPY_MODEL_ab0f9946c503444c899746425bc13548","value":"100%"}},"988b400176584890aff0e7e84d83a15d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9297d54355cb4b9984139b081958cb94","max":6,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ad3953880e8d4313be14f3a7e6e066c4","value":6}},"3c6ad6c61fa344debfd069d023dc9ec1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_65196dfe55974b17b7fd205fadd32502","placeholder":"​","style":"IPY_MODEL_d237cc82c7b64cb5a6e4240ac579aef3","value":" 6/6 [00:04&lt;00:00,  1.57it/s]"}},"76e802486bb9445e8c788b1159427bd4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ff67574f03d40ebb646150436a4b207":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab0f9946c503444c899746425bc13548":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9297d54355cb4b9984139b081958cb94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad3953880e8d4313be14f3a7e6e066c4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"65196dfe55974b17b7fd205fadd32502":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d237cc82c7b64cb5a6e4240ac579aef3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"012a1fbe10534d7d94c4f958efe15e6f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2e60133f7bba4ed7a30feccae4607143","IPY_MODEL_52f4dca172384408ae1b941487396dc3","IPY_MODEL_c1d5b1c70bd44178994b29ed820ccc74"],"layout":"IPY_MODEL_e0d0379ab2a34e8da5d89f43c7873ce5"}},"2e60133f7bba4ed7a30feccae4607143":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_92faa36a64af42bf82a50b60876cefd2","placeholder":"​","style":"IPY_MODEL_38031334fc9e4d44a274be43cc7dbcd5","value":"100%"}},"52f4dca172384408ae1b941487396dc3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fdf789cb1d042de81c08e82c61ad80d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6e43954816c941f18194da79127c9416","value":1}},"c1d5b1c70bd44178994b29ed820ccc74":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10d18aef7f6548a19abe51fbd47485b5","placeholder":"​","style":"IPY_MODEL_919bdc0e3db546e09fa622620c1012a8","value":" 1/1 [00:00&lt;00:00,  6.11it/s]"}},"e0d0379ab2a34e8da5d89f43c7873ce5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92faa36a64af42bf82a50b60876cefd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38031334fc9e4d44a274be43cc7dbcd5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1fdf789cb1d042de81c08e82c61ad80d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e43954816c941f18194da79127c9416":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"10d18aef7f6548a19abe51fbd47485b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"919bdc0e3db546e09fa622620c1012a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8201bf23e03c4408b6da739b55003b2c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8fdefb82d46542929725028da074b3b5","IPY_MODEL_4145cea1efbe4f2085d003ea35f167fc","IPY_MODEL_e4fb50288bd54b99a66e8f5d76e42ce3"],"layout":"IPY_MODEL_dbbd8efffcdb4f4e870f446a9b186946"}},"8fdefb82d46542929725028da074b3b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ab9821618c344088585a64a72aaeff1","placeholder":"​","style":"IPY_MODEL_1c268a8e25964486ae1017398cd35562","value":"100%"}},"4145cea1efbe4f2085d003ea35f167fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ebcf70f8ee14ddabcd35364a5e37f35","max":6,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2f99ade6f81f48deac9859c0fe7b9bc4","value":6}},"e4fb50288bd54b99a66e8f5d76e42ce3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b1b43e5fc2c47948d318591b3bb2aae","placeholder":"​","style":"IPY_MODEL_22b542ee51bd44fb9c0d5db4f6368ad7","value":" 6/6 [00:04&lt;00:00,  1.56it/s]"}},"dbbd8efffcdb4f4e870f446a9b186946":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ab9821618c344088585a64a72aaeff1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c268a8e25964486ae1017398cd35562":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3ebcf70f8ee14ddabcd35364a5e37f35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f99ade6f81f48deac9859c0fe7b9bc4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8b1b43e5fc2c47948d318591b3bb2aae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22b542ee51bd44fb9c0d5db4f6368ad7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"94e78eb5ef2e45dea34be0de17bb2ec3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1ca031842e5f47e59ff849c9949e8525","IPY_MODEL_4282b1838605494184874286711b5cff","IPY_MODEL_03ca3a49f62844eb804893d4683132d7"],"layout":"IPY_MODEL_fb0c3021b7e34eb5b4b9e71684cae88b"}},"1ca031842e5f47e59ff849c9949e8525":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_869b113a56304916b4f77bd9fc4a8ca0","placeholder":"​","style":"IPY_MODEL_7515dd93242744cebce610e691d4d198","value":"100%"}},"4282b1838605494184874286711b5cff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7a8968f5a5d4ec3b0bde5e14c5a1954","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_87693d0ff5154bd484bcc9e9cf478c25","value":1}},"03ca3a49f62844eb804893d4683132d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1e23cf46feb43c193b3f27725c0f8a1","placeholder":"​","style":"IPY_MODEL_a6258a2e17e54f07bfdc57e2e00233db","value":" 1/1 [00:00&lt;00:00,  6.17it/s]"}},"fb0c3021b7e34eb5b4b9e71684cae88b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"869b113a56304916b4f77bd9fc4a8ca0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7515dd93242744cebce610e691d4d198":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7a8968f5a5d4ec3b0bde5e14c5a1954":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87693d0ff5154bd484bcc9e9cf478c25":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d1e23cf46feb43c193b3f27725c0f8a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6258a2e17e54f07bfdc57e2e00233db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c820bb426109460b81073f6740958525":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_21859abbdb704f60abd8e9c9c5073deb","IPY_MODEL_399e02347546452fbc4ffbc168e4c6d4","IPY_MODEL_916d3566bbd54f05b14e36d7dfaf9bc4"],"layout":"IPY_MODEL_45b0506fc4df478d92979aa3ee351f5c"}},"21859abbdb704f60abd8e9c9c5073deb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26b23550d0ae43d5a666421855929a41","placeholder":"​","style":"IPY_MODEL_64286f0c31194488839c2a305474ff3a","value":"100%"}},"399e02347546452fbc4ffbc168e4c6d4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a24dff97ba704d16b26061cad8428bf8","max":6,"min":0,"orientation":"horizontal","style":"IPY_MODEL_84a12223503f494cb2811bd29a920d41","value":6}},"916d3566bbd54f05b14e36d7dfaf9bc4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_72771edc22524a5d8b4e813bed751cc2","placeholder":"​","style":"IPY_MODEL_998aabaee70a45faa09f9e1710728ace","value":" 6/6 [00:04&lt;00:00,  1.56it/s]"}},"45b0506fc4df478d92979aa3ee351f5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26b23550d0ae43d5a666421855929a41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64286f0c31194488839c2a305474ff3a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a24dff97ba704d16b26061cad8428bf8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84a12223503f494cb2811bd29a920d41":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"72771edc22524a5d8b4e813bed751cc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"998aabaee70a45faa09f9e1710728ace":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7cb8808b906646b2b12432eb762a2b09":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_932328b6e157405897910ea6977b2459","IPY_MODEL_5bd176ee73954865bfe9df1c311afa60","IPY_MODEL_ce7a1d51ea6249ddb37de53a740911f9"],"layout":"IPY_MODEL_9cce52c5a9ea4f7dad2c948e28d77471"}},"932328b6e157405897910ea6977b2459":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4911f5efa47d440faff3b33aaba91c62","placeholder":"​","style":"IPY_MODEL_2133bad142a242219e0e0b7603744e70","value":"100%"}},"5bd176ee73954865bfe9df1c311afa60":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d28f9aea1d14c4ea99546d4c644a8bb","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3e4f1749003e449ab3ebc7617679373a","value":1}},"ce7a1d51ea6249ddb37de53a740911f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30b999c1f7d042ff8d7f35422f8cf3ab","placeholder":"​","style":"IPY_MODEL_bdbd40078e3447a095989b191db12f3f","value":" 1/1 [00:00&lt;00:00,  6.25it/s]"}},"9cce52c5a9ea4f7dad2c948e28d77471":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4911f5efa47d440faff3b33aaba91c62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2133bad142a242219e0e0b7603744e70":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d28f9aea1d14c4ea99546d4c644a8bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e4f1749003e449ab3ebc7617679373a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"30b999c1f7d042ff8d7f35422f8cf3ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdbd40078e3447a095989b191db12f3f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}